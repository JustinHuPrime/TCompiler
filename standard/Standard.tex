\documentclass[letterpaper,12pt]{book}

\usepackage{indentfirst}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{longtable}

% Don't put two spaces after a period
\frenchspacing

\begin{document}
\title{The T Programming Language}
\author{Justin Hu}
\maketitle
\tableofcontents

\part{Language}

\chapter{Introduction}

This document specifies the syntax and semantics of the T programming language, especially for the implementation of the reference compiler for the language. T is a systems oriented, module-based programming language. The language is statically-typed, with neither classes nor a garbage collector. Conceptually, a T program consists of a set of modules, each module exposing some public interface. An implementation of T takes in the declaration files of the used modules, and code files or linkable files (distinguished in some manner\footnote{\textbf{Reference compiler behaviour}: the reference compiler distinguishes between declaration and code files using filename extensions. Declaration files have a .td extension, while code files have a .tc extension.}), each of which implement the interface for some module, and produces an executable. This executable may then be run, in some environment, to produce some sequence of effects.

\section{Copyright}

This work and all of its appendices are licensed under the Creative Commons Attribution-ShareAlike 4.0 International License. To view a copy of this license, visit http://creativecommons.org/licenses/by-sa/4.0/.

\section{Compiler Structure}

A T program is translated into an executable in several phases. Since the T grammar is not context free, it is necessary to make multiple passes over the same file. These phases are considered distinct and necessary, and are expected to be present in all compiler implementations. At any point during this process, if a requirement of the standard is violated, a diagnostic message is issued, and translation may halt.

\begin{enumerate}
	\item \textbf{Lexing}: each declaration and code file is split into a sequence of tokens.

	\item \textbf{Parsing}: the sequence of tokens is parsed into an abstract syntax tree. The parse tree produced depends on the interface of the imported modules, as well as the name of declarations contained in the current module, including those declared after the current point in time in the import or file scope, this phase is split into three parts.
	\begin{enumerate}
		\item Every import or file scope declaration is parsed, but function bodies remain unparsed.
		
		\item Each file scope declaration and import is inspected, and the details for the identifiers introduced are recorded. What an identifier at top level references is resolved at this point.
		
		\item Each unparsed function body is then parsed using the information from the first and second pass, while simultaneously, details about any declarations are recorded. What an identifier references is resolved at this point.
	\end{enumerate}

	\item \textbf{Typechecking}: the program is checked for static type consistency and correctness.
	
	\item \textbf{Translation}: each code module is translated into a linkable form. This is usually an object code file. The reference compiler translates in several steps.
	\begin{enumerate}
		\item \textbf{Source Code Optimization}: optimizations are performed on the source code's abstract syntax tree. Currently, no optimizations at this level are performed.
		
		\item \textbf{Translation to IR}: each code module is translated into a three-address code form intermediate representation. This translation is independent of the target environment.
		
		\item \textbf{IR Optimization}: optimizations are performed on the intermediate representation. Currently, no optimizations at this level are performed.
		
		\item \textbf{Assembly Generation}: each code module (currently in an intermediate representation) is translated to architecture and environment-specific assembly code. This assembly code, however, does not yet have its stack frames laid out or its register usage resolved.
		
		\item \textbf{Assembly Optimization (part 1)}: optimizations are performed on the register-independent assembly. Currently, no optimizations at this level are performed.
		
		\item \textbf{Register Allocation}: the register usage for each function is resolved, and stack frames are laid out.
		
		\item \textbf{Assembly Optimization (part 2)}: optimizations are performed on the penultimate assembly code. Currently, no optimizations at this level are performed.
		
		\item \textbf{Assembling}: the generated assembly code is assembled into a linkable form. In the reference compiler, this is handled externally by the system assembler. (In Linux, this is the command \texttt{as}.)
	\end{enumerate}
	
	\item \textbf{Linking (optional)}: the generated and supplied are linked into an executable program, or into a shared library. This step is optional if the user wants to produce several object files. In the reference compiler, this is handled externally by the system linker or object-file archiver. (In Linux, these are the commands \texttt{ld} or \texttt{ar}.)
\end{enumerate}

\section{Environment}

A T program is compiled for one or more execution environments, in some translation environment. These environments do not have to be the same. The translation environment must be capable of providing files to the compiler, and must be capable of providing diagnostic messages to the user. The execution environment must be capable of starting execution by calling the main function, and providing the appropriate command line arguments. The environment will be affected by the program through side effects. These side effects must be visible according to the defined semantics. The execution environment must also be capable of handing the return value from the main function. Additionally, the environment must be capable of supporting the implementation and side effects of any standard library modules imported.

\subsection{Character Sets}

In addition to the general requirements above, the translation environment has a character set. This character set must be able to represent at least the printable (alphanumeric, symbols) ASCII characters, the space, and the newline\footnote{\textbf{Reference compiler behaviour}: the reference compiler treats ASCII as its source character set. It defines newline as either the ASCII line feed, the ASCII carriage return, or the ASCII carriage return followed by the ASCII line feed.}. Almost all operating systems provide this environment. The execution environment has its own, possibly distinct character set. There are no requirements on what this character set contains. For the most part, that character set is Unicode.

\chapter{Lexicon}

A source file consists of a sequence of characters. The lexing phase splits these into tokens based on the lexical syntax, and translates magic tokens into literal values. The lexical syntax is strict maximal munch. A source file is described by the EBNF given in Appendix A - Lexicon. The source file must conform to this syntax, or else a diagnostic message must be issued.

\section{Magic Tokens}

As noted in Appendix A, there are three magic tokens. Magic tokens are literal values computed during lexing. The values of these magic tokens are specified below.

\begin{itemize}
	\item \texttt{\_\_FILE\_\_}: this token is replaced with a string literal containing the name of the file being processed.
	
	\item \texttt{\_\_LINE\_\_}: this token is replaced with an unsigned integer literal containing the current line in the file being processed.
	
	\item \texttt{\_\_VERSION\_\_}: this token is replaced with a string literal containing the compiler version string. This string does not have any particular format, but is human-readable.
\end{itemize}

\chapter{Syntax}

A source file, once converted into a sequence of tokens, is then converted into a tree of tokens. The provided grammar is context sensitive, and requires at least two passes to parse, since there are disambiguation rules depending on information about the declaration site of a token. However, other than the disambiguation rules, the grammar is capable of LL(1) parsing. As with the lexing phase, any deviations from the grammar must result in a diagnostic message being issued.

The grammar for a file, without disambiguation rules, is given in Appendix B - Syntax. This grammar uses the definitions for given in the lexicon.

\section{Disambiguation}

The above grammar is intended to contain two ambiguities that prevent it from being an LL(1) context free grammar:

\begin{enumerate}

	\item It is not possible to determine if an encountered identifier or scoped identifier starts a variable declaration statement or if it starts an expression (in some cases it is impossible to determine if an encountered statement is a variable declaration statement or an expression statement). As such, the parser must determine if the encountered identifier or scoped identifier is a type, and if it is a type, parse a variable declaration statement.
	
	\item There is no difference between a variable declaration and a variable definition without initialization. Contextually, variable declarations may only exist in declaration files, and variable definitions may only exist in code files.
\end{enumerate}

\section{Additional Context Requirements}

In addition to the restrictions placed by the grammar above:
\begin{itemize}
	\item no function definitions may exist within a declaration file,
	\item no function definition or declaration may have an optional argument (\texttt{"=", literal}) before a non-optional argument,
	\item no break statement may exist unless in the body of a loop or switch,
	\item no continue may exist unless in the body of a loop,
	\item no switch statement may contain more than one default case.
\end{itemize}

If a source file violates any of these requirements, a diagnostic message must be issued.

\chapter{Modules}

In T, a program is comprised of a series of modules, linked together. A module is described by its declaration file and its implementation. This implementation may be a code file, or a linkable file that contains the translation of a code file. Modules have an optional one-to-one correspondence with declaration files, and a one-to-many correspondence with code files. A translation including a linkable file shall be equivalent to one involving the original code files if no diagnostic messages would have been issued for the original code files. A module contains a set of declarations and a set of definitions.

It is possible to have a module with one declaration file or a module with no declaration file. A module with no declaration file cannot be imported by any other module, but no other module may have the same name as the module without a declaration file.

\section{Scopes}

Scopes are a mechanism to control the visibility of identifiers. A scope is a container for identifiers and other scopes. All identifiers immediately within a scope must be unique. Identifiers from containing scopes are shadowed by identifiers in the current scope, and identifiers from contained scopes are not visible. A file defines two scopes: the import scope, and the file scope. The file scope resides within the import scope, and in code files, automatically contains the identifiers declared in its corresponding declaration file (if any), only as a plain identifier. Other ways of starting a scope are discussed alongside the relevant syntactic constructs. Normally, identifiers in a scope are only visible after they are declared, but within a file scope, identifiers are visible throughout the whole scope.\footnote{The ordering and extent of identifiers within the scope is irrelevant for import scopes, since there is no possibility of using anything imported in the middle of the import list.}

\subsection{Imports}

Modules may import other modules. This means the identifiers from the module are made visible in the importing module's import scope, both as a scoped identifier consisting of the imported module name combined with the imported identifier in a scope resolution operator, and as the plain identifier. If two identifiers collide in the import scope as plain identifiers, neither is imported as a plain identifier. If there is still a collision between the scoped identifiers, then a diagnostic is to be issued\footnote{This is to make the imported identifiers visible in at least one way, but there still exists the possibility of a collision - if module \texttt{foo} has an enumeration called \texttt{bar} with an element \texttt{baz}, then the module \texttt{foo::bar} with an identifier \texttt{bar} would collide. Since the modules sharing a prefix are, to humans, part of the same library, the potential for such a collision is considered as bad code style on the part of the library authors.}.

\subsection{Opaque Type Declarations}

The only exception to the requirement that no identifiers in the same scope have the same name is when dealing with opaque type declarations (see \ref{section:Opaque Type Declarations}), which may be redefined only if the opaque type was introduced to the scope from the implicit import.

\section{Module Header}

Each module begins with a module line, that sets the name of the module. Module names are completely independent of file name. If a code file and a declaration file share this name, the code file is considered implementation for the declaration file. After the module line, each file has a list of modules that it imports into its import scope. This module line may not be a reserved identifier. Reserved identifiers may be used by the language implementation. A reserved identifier is any identifier that starts with two underscores. This includes cases where the reserved identifier is part of a larger scoped identifier that does not start with two underscores.

\section{Module Body}

A module body consists of either a set of declarations (for declaration files), or a set of declarations and definitions (for code files). In either case, an empty set is permissible.

\subsection{Declaration Files}

In declaration files, the set of declarations is the public interface for the module. Any code file importing the declaration file will have these identifiers available in the import scope, and any code file will have these identifiers available in the file scope.

\subsection{Code Files}

In a code file, declarations are not visible outside of the file. However, definitions for the declarations in the module may be supplied. Definitions may only be supplied in a code file. A definition for an identifier must define that identifier. If the code file implements a declaration file, then all identifiers within the declaration file are imported into the file scope for the code file. As an example, if there are three files, \texttt{foo.tc}, \texttt{foo.td}, \texttt{bar.td}, part of modules \texttt{foo}, \texttt{foo}, and \texttt{bar}, and both \texttt{foo.td} and \texttt{bar.td} declare the existence of the identifier \texttt{baz}, if \texttt{foo.tc} imports \texttt{bar}, it may use \texttt{baz} or \texttt{foo::baz} to refer to the \texttt{baz} from \texttt{foo.td}, and may only use \texttt{bar::baz} to refer to the \texttt{baz} from \texttt{bar.td}. This does not, however, grant any code file implementing some module additional access beyond that specified in the declaration file to the contents of any other code file implementing the same module.

\chapter{Types}

T is a statically typed language. This means that every variable has a type associated with it, and every function has a signature associated with it, and that these types and signatures are known and checked when a module is compiled. Types determine the semantics of operations on a value of that type.

\section{Basic Data Types}

T has several basic data types, listed below. These types are named in their corresponding keyword. The execution environment must be capable of supporting all data types listed below, or else the execution environment is considered non-standard. It is required for a compiler to issue a diagnostic message if compiling to a non-standard environment when encountering an unsupported type.

\begin{itemize}
	\item \texttt{void}: indicates a value of no type. This type is only used to construct other types, and is not valid on its own. This type has a size of one byte.
	
	\item \texttt{ubyte}: an unsigned integral value, one byte wide. It is assumed that bytes contain eight bits.
	
	\item \texttt{byte}: a 2's complement signed integral value, one byte wide.
	
	\item \texttt{char}: an unsigned integral value of sufficient width to contain one byte, and the narrowest character(s) within the execution environment's character set\footnote{Generally, this is one byte wide on Unicode systems.}.
	
	\item \texttt{ushort}: an unsigned integral value, two bytes wide.
	
	\item \texttt{short}: an 2's complement signed integral value, two bytes wide.
	
	\item \texttt{ushort}: an unsigned integral value, two bytes wide.
	
	\item \texttt{short}: an 2's complement signed integral value, two bytes wide.
	
	\item \texttt{uint}: an unsigned integral value, four bytes wide.
	
	\item \texttt{int}: an 2's complement signed integral value, four bytes wide.
	
	\item \texttt{wchar}: an unsigned integral value of sufficient width to contain the widest character(s) within the execution environment's character set\footnote{Generally, this is four bytes wide on Unicode systems.}.
	
	\item \texttt{ulong}: an unsigned integral value, eight bytes wide.
	
	\item \texttt{long}: an 2's complement signed integral value, eight bytes wide.
	
	\item \texttt{float}: an IEEE 754 binary32 floating point number.
	
	\item \texttt{double}: an IEEE 754 binary64 floating point number.
	
	\item \texttt{bool}: a boolean value. This type has a size of one byte, and stores either \texttt{true} or \texttt{false}. The representation of \texttt{true} shall be the integral value one, and the representation of \texttt{false} shall be the integral value zero.
\end{itemize}

\section{Defined Data Types}

There are several defined data types. These need to be declared to exist, and are given a name.

\begin{itemize}
	\item \texttt{struct}: this keyword introduces a structure type. A structure type consists of a number of fields, each having its own type. A structure is a collection of values of the given type, in the given order, and treated as one unit. Structures are not necessarily sequential in memory, as there may be padding inserted between fields to align fields for the execution environment. The address of a structure type value is the same as the address of the first element.
	
	\item \texttt{union}: this keyword introduces a union type. A union type represents a value of one of the union option types. Union types will reinterpret the given value if accessed through a non-active member. This reinterpretation is a direct reinterpretation of raw memory. A union type has the size of the largest element, and is padded to the largest padding required for the element. The address of a union type value is the same as the address of the contained value.
	
	\item \texttt{enum}: this keyword introduces an enumeration. An enumeration is a set of signed integral constants. These integral constants may take any value, but are sequentially valued, starting from zero, unless overridden (\texttt{"=", extended\_int\_literal}). When overridden, subsequent entries continue the sequential numbering from the overridden entry. If the overriding of sequential numbering causes a collision between two identifiers, then a diagnostic message must be issued.
	
	\item \texttt{typedef}: this keyword introduces a type alias. A type alias is a name for a type, usually a derived type. A type alias is treated as a new, unique, fundamental data type, meaning that a type alias value may not be treated as if it were its unaliased type. However, a type alias value may be converted into the unaliased type with a cast expression.
\end{itemize}

\section{Derived Data Types}

Any data type may form the base of a derived data type.

\begin{itemize}
	\item \textbf{Constants}: by appending \texttt{const} to a type, a type may be turned into a constant type. A value of a constant type may not be written to directly. If a constant value is written to, a diagnostic message must be issued. If a constant value is written to indirectly (e.g. through a casted pointer), undefined behaviour results, and no diagnostic message is required. The ordering of \texttt{const} and \texttt{volatile} in a declaration is irrelevant. A void base type is not allowed.
	
	\item \textbf{Volatiles}: by appending \texttt{volatile} to a type, a type may be turned into a volatile type. Reads and writes from and to a value of volatile type are considered side effects, and must be sequenced. The ordering of \texttt{const} and \texttt{volatile} in a declaration is irrelevant. A void base type is not allowed.
	
	\item \textbf{Arrays}: by appending a positive or unsigned extended integral constant in square brackets, a type is turned into an array of that many items. An array is guaranteed to be contiguous in memory, such that by adding (without pointer arithmetic, i.e. on the raw integer address) the size of an element, to the address of an element, you get the address of the next element. Arrays of void are not allowed.
	
	\item \textbf{Pointers}: by appending \texttt{*} to a type, a type is turned into a pointer to that type. Pointers hold an unsigned integer (width determined by the execution environment) that represents the location in memory 
	
	\item \textbf{Function Pointers}: by appending a comma separated list of types enclosed in parentheses, with optional and ignored names, a type is turned into a function pointer to a function returning that type (which may be void), and taking the list of types as arguments. Function pointers also hold an unsigned integer (width determined by the execution environment) that represents the location in memory.
\end{itemize}

\chapter{Declarations}

\lstinputlisting[breaklines=true, firstline=9, lastline=16]{"Appendix B - Syntax.ebnf"}

Declarations state the existence of a type, function, or variable in the current module. For type declarations, they may also serve as the definition of a type. Conceptually, a declaration is all that is required to use the declared entity, and the user need not be aware of the definition. However, for non-opaque types, it is necessary to know the definition of the type to use it completely - it is necessary to know the size of a type to declare it on the stack. For opaque types, it is not necessary to have that additional information, so both kinds of declarations - complete and opaque - are considered declarations.

The identifier in a declaration may not be a reserved identifier. Reserved identifiers may be used by the language implementation. Any identifier that starts with two underscores is considered reserved.

\section{Function Declarations}

\lstinputlisting[breaklines=true, firstline=21, lastline=21]{"Appendix B - Syntax.ebnf"}

A function declaration declares the existence of the function, having the name in the first identifier, and provides the interface to call the function and get a return value. The parameter names are not significant, and may be different from the names used in the function definition. The return type and formal parameter types must be complete types, except that a return value of \texttt{void} indicates that the function does not return any value. If a formal parameter is followed by an equals sign and a literal value, then any callers of this function may omit the value in the function call expression, and the default value will be substituted in as the actual argument. However, function pointers are unable to use default parameters, so when converted to a function pointer, it will be as if no default parameters were specified. The corresponding function definition must supply the same default parameters as those specified in the declaration.

Multiple function definitions with the same name form an overload set. When resolving a function name, the overload set to reference is first resolved, then the function within the overload set is resolved. An overload set contains multiple functions with the same name, but different argument types. An overload set must not contain multiple functions such that they cannot be distinguished when called with any valid list of argument types - that is, there must be no more than one function per signature.

When resolving within an overload set, once the overload set is resolved\footnote{This means that two overload sets both named \texttt{foo} will have to be resolved using scope-resolution operators even if the argument types uniquely identify one particular overload.}, the list of argument types is generated. When resolving for use in a function pointer, the argument type list is compared against the list of types in the overload set, and must match exactly. Otherwise, when resolving for use in a direct call:
\begin{enumerate}
	\item The list of types is matched exactly against all overload argument types, allowing for optional arguments. If there is more than one exact match, a diagnostic must be issued. If there is one exact match, that overload is used, otherwise, proceed to the next step.
	
	\item The list of types is matched with casting against all overload argument types, allowing for optional arguments. The match with the least casting required is preferred. If there is more than one most preferred match, a diagnostic must be issued. If there is one exact match, that overload is used, otherwise, there is no valid overload for the given list of argument types.
\end{enumerate}

\subsection{Main Functions}\label{subsection:Main Functions}

Any function named 'main' is considered a main function. The main function does not need to be declared. Only one main function may be declared or defined per executable, but it is irrelevant in which module the main function is declared or defined. A main function may have zero or two parameters. If there are two parameters, the first parameter must be a \texttt{uint} and the second parameter must be a pointer to pointer to \texttt{char}. A diagnostic must be issued if the main function does not have the correct parameter count or types. The first parameter will hold the number of command line arguments and the second will hold either \texttt{null}, if there are no command line arguments, or a pointer to a list of null-terminated character strings listing the command line arguments. If there are any command line arguments, then the zeroth represents the name of the program, while the remaining are the command line arguments. Additionally, the main function must return an \texttt{int}. A diagnostic must be issued if the return type of main is not \texttt{int}.

\section{Variable Declarations}

\lstinputlisting[breaklines=true, firstline=22, lastline=22]{"Appendix B - Syntax.ebnf"}

A variable declaration declares the existence of a global variable. Variable declarations may use an incomplete type (the corresponding definition must not use an incomplete type). The comma separated list of identifiers lists out the names declared as a variable.

\section{Opaque Type Declarations}\label{section:Opaque Type Declarations}

\lstinputlisting[breaklines=true, firstline=23, lastline=23]{"Appendix B - Syntax.ebnf"}

An opaque type declaration declares the existence of a user-defined type (structure, union, enumeration, or alias). Other than the existence of that type as a user-defined type, and the name, nothing else is specified.

\section{Struct Type Declarations}

\lstinputlisting[breaklines=true, firstline=24, lastline=24]{"Appendix B - Syntax.ebnf"}

A structure type declaration defines a structure type. Each variable declaration has a set of identifiers that it declares, and each of those identifiers is a field, with the type corresponding to the type of the variable declaration.

\section{Union Type Declarations}

\lstinputlisting[breaklines=true, firstline=25, lastline=25]{"Appendix B - Syntax.ebnf"}

A union type declaration defines a union type. Each variable declaration has a set of identifiers that it declares, and each of those identifiers is an option for the union, with the type corresponding to the type of the variable declaration.

\section{Enum Type Declaration}

\lstinputlisting[breaklines=true, firstline=26, lastline=26]{"Appendix B - Syntax.ebnf"}

An enumeration declaration defines an enumeration type. Each identifier is a separate enumeration constant, with either an automatically set or manually set value. Numbering of constants is sequential from the previous manually set value, or zero, if no manually set value has been encountered.

\section{Typedef Declaration}

\lstinputlisting[breaklines=true, firstline=27, lastline=27]{"Appendix B - Syntax.ebnf"}

A typedef declaration introduces a type alias. This type alias is treated as if it were an atomic type, disallowing any decomposition. However, the a value of this type may be cast into the original type, allowing for decomposition after a cast.

\chapter{Definitions}

\lstinputlisting[breaklines=true, firstline=6, lastline=8]{"Appendix B - Syntax.ebnf"}

Definitions provide the value of a declared variable or function. Only code files may contain definitions, and in a code file, no variable declarations are allowed. Within a code file, it is permissible to have a definition without an attached declaration. If there is no corresponding declaration, or if the declaration is in the same code file, then the 

\section{Function Definitions}

\lstinputlisting[breaklines=true, firstline=18, lastline=18]{"Appendix B - Syntax.ebnf"}

A function definition specifies the code for a function, in the compound statement. Additionally, the definition introduces two scopes - one from the compound statement, the function body, and the second, a scope containing the formal parameters. The formal parameter scope contains the function body scope. Any function named 'main' is considered a main function, and is subject to the limits described in \ref{subsection:Main Functions}.

\section{Variable Definitions}

\lstinputlisting[breaklines=true, firstline=19, lastline=19]{"Appendix B - Syntax.ebnf"}

A variable definition creates a variable, and optionally initializes the variable. If the variable is not initialized, then its value is undefined. Access to uninitialized variables is considered undefined behaviour.

\chapter{Statements}

\lstinputlisting[breaklines=true, firstline=29, lastline=47]{"Appendix B - Syntax.ebnf"}

Statements are units of execution that generally involve either side effects or flow control. Additionally, a statement may be a type or variable definition. These types or variables exist only within the containing scope.

\section{Compound Statements}

\lstinputlisting[breaklines=true, firstline=49, lastline=49]{"Appendix B - Syntax.ebnf"}

The compound statement introduces a scope, and additionally bundles a set of statements into one statement.

\section{If Statements}

\lstinputlisting[breaklines=true, firstline=50, lastline=50]{"Appendix B - Syntax.ebnf"}

An if statement dynamically chooses between the execution of two statements, or between executing a statement or not executing a statement. There are two forms to the if statement: the first form where there is no else, and the statement executes the statement if and only if the condition expression is true. The second form is when there is an else. The if statement will execute the first statement if and only if the condition is true, and the second statement otherwise. The condition must result in a boolean value.

The construct known as an else-if is a special case of the else statement: an else-if is just an if statement as the only statement in the else of the first if statement. There is no need for additional syntactic support for the else-if construct.

\section{While Loop Statements}

\lstinputlisting[breaklines=true, firstline=51, lastline=51]{"Appendix B - Syntax.ebnf"}

A while loop statement repeatedly executes the statement, checking the condition (must be a boolean expression) beforehand, and leaving the loop without executing the statement if and only if the expression is false.

\section{Do-While Loop Statements}

\lstinputlisting[breaklines=true, firstline=52, lastline=52]{"Appendix B - Syntax.ebnf"}

A do-while loop statement repeatedly executes the statement, checking the condition (must be a boolean expression) afterwards, and leaving the loop if and only if the expression is false
\footnote{Unlike C, the do-while loop does not expect a semicolon after the while.}.

\section{For Loop Statements}

\lstinputlisting[breaklines=true, firstline=53, lastline=53]{"Appendix B - Syntax.ebnf"}

The for loop statement introduces a scope, and within that scope, the variable declaration statement resides. If the initializer is an expression, then the expression is evaluated for side-effect. Next, before each iteration of the loop, the condition is checked, then the loop body runs, then the increment expression is evaluated for side effects. Execution returns to checking for the condition. If the condition is false, the loop ends, and the increment is not run. Additionally, a continue statement will only jump to the increment expression - i.e. the end of the loop body.

\section{Switch Statements}

\lstinputlisting[breaklines=true, linerange={54-54, 61-62}]{"Appendix B - Syntax.ebnf"}

A switch statement selects between several possible cases. The expression is evaluated, and it must be an integral expression. Then, the matching case is selected, and the matching statement is executed. Then, unless execution hits a break, execution proceeds down the following cases. If no case is matched, then the default and its statement is executed, and execution of the switch continues down the remaining cases. It is an error to have multiple cases with the same value. Additionally, despite the curly braces, the switch itself does not define an actual scope.

\section{Break Statements}

\lstinputlisting[breaklines=true, firstline=55, lastline=55]{"Appendix B - Syntax.ebnf"}

A break statement will leave a loop or a switch statement. The break statement jumps to the first statement after the end of the loop or switch.

\section{Continue Statements}

\lstinputlisting[breaklines=true, firstline=56, lastline=56]{"Appendix B - Syntax.ebnf"}

A continue statement will jump to the end of the body of a loop. Note that in a for loop, the continue statement will not skip over the increment, as that comes just after the body.

\section{Return Statements}

\lstinputlisting[breaklines=true, firstline=57, lastline=57]{"Appendix B - Syntax.ebnf"}

A return statement returns from the current function. If an expression is provided, it must match the return type of the function, and the value of the expression will be the returned value. If a value is not provided, then the function must be void, or the value must have been provided in some other way - almost certainly through inline assembly.

\section{Assembly Statements}

\lstinputlisting[breaklines=true, firstline=58, lastline=58]{"Appendix B - Syntax.ebnf"}

An assembly statement inserts the assembly code into the generated assembly. The string literal respects escape codes, but is otherwise inserted verbatim. It is the responsibility of the user to write valid assembly code.

\section{Variable Declaration Statements}

\lstinputlisting[breaklines=true, firstline=59, lastline=59]{"Appendix B - Syntax.ebnf"}

A variable declaration statement creates a variable, and optionally initializes the variable with an expression. If it is not initialized, then its value is undefined. The variable exists in the enclosing scope.

\section{Expression Statement}

\lstinputlisting[breaklines=true, firstline=60, lastline=60]{"Appendix B - Syntax.ebnf"}

The expression statement is an expression followed by a semicolon. The expression is evaluated for side-effects, and only side-effects.

\section{Empty Statement}

The empty statement is a single semicolon. It represents doing nothing, and is used only as a placeholder.

\chapter{Expressions}

Expressions perform computations and produce values. Generally, an expression involves an operator and one or more sub-expressions. Below is a summary of the operators, their associativities, and their precedences (lower precedence numbers bind less tightly). This table is derived from the grammar.

\begin{longtable}{|c|c|c|c|}
\hline
\textbf{Operator} & \textbf{Description} & \textbf{Associativity} & \textbf{Precedence}\\
\hline
\texttt{,} & sequencing & left to right & 1\\
\hline
\texttt{=} & assignment & right to left & 2\\
\hline
\texttt{*=} & compound multiplication-assignment & right to left & 2\\
\hline
\texttt{/=} & compound division-assignment & right to left & 2\\
\hline
\texttt{\%=} & compound modulo-assignment & right to left & 2\\
\hline
\texttt{+=} & compound addition-assignment & right to left & 2\\
\hline
\texttt{-=} & compound subtraction-assignment & right to left & 2\\
\hline
\texttt{<<=} & compound left-shift-assignment & right to left & 2\\
\hline
\texttt{>>=} & compound arithmetic-right-shift-assignment & right to left & 2\\
\hline
\texttt{>>>=} & compound logical-right-shift-assignment & right to left & 2\\
\hline
\texttt{\&=} & compound bitwise-and-assignment & right to left & 2\\
\hline
\texttt{\^{}=} & compound bitwise-exclusive-or-assignment & right to left & 2\\
\hline
\texttt{|=} & compound bitwise-or-assignment & right to left & 2\\
\hline
\texttt{\&\&=} & compound logical-and-assignment & right to left & 2\\
\hline
\texttt{||=} & compound logical-or-assignment & right to left & 2\\
\hline
\texttt{?:} & ternary conditional & right to left & 3\\
\hline
\texttt{\&\&} & logical and & left to right & 4\\
\hline
\texttt{||} & logical or & left to right & 4\\
\hline
\texttt{\&} & bitwise and & left to right & 5\\
\hline
\texttt{|} & bitwise or & left to right & 5\\
\hline
\texttt{\^{}} & bitwise exclusive-or & left to right & 5\\
\hline
\texttt{==} & equality & left to right & 6\\
\hline
\texttt{!=} & inequality & left to right & 6\\
\hline
\texttt{<} & less than & left to right & 7\\
\hline
\texttt{>} & greater than & left to right & 7\\
\hline
\texttt{<=} & less than or equal to & left to right & 7\\
\hline
\texttt{>=} & greater than or equal to & left to right & 7\\
\hline
\texttt{<=>} & three-way comparison & left to right & 8\\
\hline
\texttt{<<} & left shift & left to right & 9\\
\hline
\texttt{>>} & arithmetic right shift & left to right & 9\\
\hline
\texttt{>>>} & logical right shift & left to right & 9\\
\hline
\texttt{+} & addition & left to right & 10\\
\hline
\texttt{-} & subtraction & left to right & 10\\
\hline
\texttt{*} & multiplication & left to right & 11\\
\hline
\texttt{/} & division & left to right & 11\\
\hline
\texttt{\%} & modulo & left to right & 11\\
\hline
\texttt{*} & dereference & right to left & 12\\
\hline
\texttt{\&} & address of & right to left & 12\\
\hline
\texttt{++} & pre-increment & right to left & 12\\
\hline
\texttt{--} & pre-decrement & right to left & 12\\
\hline
\texttt{-} & negation & right to left & 12\\
\hline
\texttt{!} & logical not & right to left & 12\\
\hline
\texttt{\~{}} & bitwise not & right to left & 12\\
\hline
\texttt{.} & member access & left to right & 13\\
\hline
\texttt{->} & pointer member access & left to right & 13\\
\hline
\texttt{()} & function call & left to right & 13\\
\hline
\texttt{[]} & array index & left to right & 13\\
\hline
\texttt{++} & post-increment & left to right & 13\\
\hline
\texttt{--} & post-decrement & left to right & 13\\
\hline
\texttt{=-} & in-place negate & left to right & 13\\
\hline
\texttt{=!} & in-place logical not & left to right & 13\\
\hline
\texttt{=\~{}} & in-place bitwise not & left to right & 13\\
\hline
\end{longtable}

\section{Operators}

Operators combine one or more expressions, and produce a value. See the above for a list of all operators and their precedences and associativities. Below is a summary of the effects of the operators:

\subsection{Sequencing Operator}

\lstinputlisting[breaklines=true, firstline=65, lastline=67]{"Appendix B - Syntax.ebnf"}

The sequencing operator (\texttt{,}), evaluates the left hand side for side-effects, and evaluates the right hand side for a value, and produces that value.

\subsection{Assignment Operators}

\lstinputlisting[breaklines=true, firstline=68, lastline=83]{"Appendix B - Syntax.ebnf"}

The plain assignment operator (\texttt{=}) evaluates the left hand side as a value to assign to, then evaluates the right hand side as a value, and assigns the result of the right hand side to the result of the left hand side.

The other assignment operators are the compound assignment operators. These evaluate the left hand side as a value to be assigned to, retrieve its value, evaluate the right hand side, perform the operation on the two values, and assign the result to the left hand side. The left hand side will only be evaluated once.

Assignment does not require the types to match, but restrictions are applied on the types of values that may be assigned to one another. When assigning two types that do not exactly match, an implicit cast is performed. Additionally, an aggregate initializer, which has no type, may be used in an assignment as well. See Appendix A - Assignability for a table detailing these rules.

\subsection{Ternary Conditional Operators}

\lstinputlisting[breaklines=true, firstline=84, lastline=86]{"Appendix B - Syntax.ebnf"}

The ternary operator acts like an if statement for expressions. It evaluates the left hand side, and if and only if the left hand side is true, it will evaluate the middle expression and produce its value. Otherwise, it will evaluate the right hand expression and produce its value. Only one of the two expressions will be evaluated. The resulting value is converted to a type that can hold the type of either branch of the expression. See Appendix C - Expression Type Merging for a table detailing these rules.

\subsection{Logical Operators}

\lstinputlisting[breaklines=true, firstline=87, lastline=87]{"Appendix B - Syntax.ebnf"}

Logical operators operate on boolean values. The logical-and operator (\texttt{\&\&}) evaluates the left hand side. If the left hand value is false, it does not evaluate the right hand side, and produces false. If the left hand value is true, it produces the value of the right hand side. The logical-or operator (\texttt{||}) evaluates the left hand side. If the left hand value is true, it does not evaluate the right hand side, and produces true. If the left hand value is false, it produces the value of the right hand side.

\subsection{Bitwise Operators}

\lstinputlisting[breaklines=true, firstline=88, lastline=88]{"Appendix B - Syntax.ebnf"}

Bitwise operators operate on integer values (\texttt{ubyte}, \texttt{byte}, \texttt{ushort}, \texttt{short}, \texttt{uint}, \texttt{int}, \texttt{ulong}, \texttt{long}). Additionally, before performing any bitwise operations, the values are converted according to Appendix C, and then the operation is performed.

\subsection{Comparison Operators}

\lstinputlisting[breaklines=true, firstline=89, lastline=90]{"Appendix B - Syntax.ebnf"}

There are two kinds of comparison operators - equality comparison operators (\texttt{==}, \texttt{!=}), and relational comparison operators (\texttt{<}, \texttt{>}, \texttt{<=}, \texttt{>=}). All comparison operators first convert the types into a common type (see Appendix D - Comparison Type Merging for details). These comparisons are only valid on base types that are numeric, characters, booleans, or pointers. The comparisons check for numeric equality, inequality, or numeric relations. The result is a boolean value.

\subsection{Three-Way Comparison Operators}

\lstinputlisting[breaklines=true, firstline=91, lastline=91]{"Appendix B - Syntax.ebnf"}

The three-way comparison operator expects its inputs to be numeric, characters, booleans, or pointers. It evaluates both inputs, and converts them to a common type (see Appendix D). Then, it compares these inputs. If the left hand side is less than the right hand side, it produces -1, if they are equal, 0, and if the left hand side is greater than the right hand side, it produces 1. The inputs are only evaluated once, and the output is a \texttt{byte}.

\subsection{Shift Operators}

\lstinputlisting[breaklines=true, firstline=92, lastline=92]{"Appendix B - Syntax.ebnf"}

The shift operators expect an integral value for their left hand side, and an unsigned integral value for their right hand side. Performing no conversion, the value is bit-shifted by the number of bits given in the right hand side value. This value must be less than the number of bits in the left hand side value. In case of a left-shift operator (\texttt{<<}) or a logical-right-shift operator (\texttt{>>>}), the value is zero-filled. In case of an arithmetic-right-shift operator (\texttt{>>}), the value is sign-filled.

\subsection{Addition Operators}

\lstinputlisting[breaklines=true, firstline=93, lastline=93]{"Appendix B - Syntax.ebnf"}

Addition and subtraction expressions both support two numeric operands, in which case they will evaluate the left hand side, then the right hand side, convert to a common type (see Appendix C), and the result is produced after applying the relevant operator. However, when adding a data pointer and an integer (order irrelevant), both are evaluated, and then the integer is multiplied by the size of the type the pointer points to before being added to the pointer. It is also acceptable to subtract an integer from a data pointer (but not the other way around), and the subtracted value is also first multiplied by the size of what the pointer points to before being subtracted from the pointer. Finally, if two pointers are subtracted, then their difference is divided by the size of the type the pointers point to before being produces. Both pointers must point to the same type.

\subsection{Multiplication Operators}

\lstinputlisting[breaklines=true, firstline=94, lastline=94]{"Appendix B - Syntax.ebnf"}

Multiplication expressions operate on numeric values. The left hand side, then the right hand side are evaluated, these values are converted to a common type (see Appendix C), and the result is produced after applying the relevant operator.

\subsection{Prefix Operators}

\lstinputlisting[breaklines=true, firstline=95, lastline=103]{"Appendix B - Syntax.ebnf"}

The dereference operator (\texttt{*}) takes the expression (must be a data pointer), and produces an assignable value from that expression. The result is of the base type of the pointer.

The address-of operator (\texttt{\&}) takes the expression (must be an assignable value), and produces an address from that expression. The resulting type is a pointer whose base type is the type of the assignable value.

The pre-increment and pre-decrement operators (\texttt{++}, \texttt{--}) take the expression (must be an assignable value, and either numeric or a pointer), and if it is numeric, increments or decrements it by one, if it is a data pointer, adds or subtracts the size of the type the pointer points to. The value produces is that after the increment.

The negation operator takes the expression (must be a numeric value and not an unsigned long), and negates it. If a signed integral or floating point value is negated, the resulting type remains the same. If an unsigned integral value is negated, the resulting type is the smallest signed type that can hold the entire range when negated, i.e. the next largest signed type (e.g. a negated \texttt{ubyte} produces a \texttt{short}).

The logical-not operator takes the expression (must be a boolean value), and negates it. Its type is unchanged.

The bitwise-not operator takes the expression (must be an integral value), and flips each bit in the expression. Its type is unchanged.

\subsection{Postfix Operators}

\lstinputlisting[breaklines=true, linerange={104-104, 112-112}]{"Appendix B - Syntax.ebnf"}

The member-access operator (\texttt{.}) takes a value of a type with members (structures or unions), and produces the named member. This value is assignable if the original value is assignable. The pointer member-access operator (\texttt{->}) takes a value of a pointer to a type with members, and produces the named member after dereferencing the pointer. Only the accessed member is accessed via the pointer. The produced value is always assignable. The type of this expression is the type of the member.

The function-call operator (\texttt{()}) takes a value that is either a function pointer or a function name, evaluates it, a comma separated list of assignment expressions (sequencing operators, if used, must be surrounded by parentheses), evaluated in an unspecified order, and calls the function or function pointer with the argument list. The produced type is that of the return value of the function. If the function returns void, then this must have been evaluated for side-effect only.

The array-index operator (\texttt{[]}) takes a value that is either a pointer or an array, evaluates that, and an integral index, evaluates that, and produces either that element in the array, if the value is an array, or the dereference of the sum (with pointer arithmetic as for the addition operator) of the pointer and the index.

The post-increment and post-decrement operators (\texttt{++}, \texttt{--}) produce the value, then increment it or decrement it exactly like a pre-increment or pre-decrement operator. The value is only evaluated once.

The in-place unary operators take the value, performs the unary operation on it, stores it, and produces the result of the unary operation. The in-place negation operator (\texttt{=-}) performs a negation on a numeric value, the in-place logical not operator (\texttt{=!}) performs a logical not on a boolean value, and the in-place bitwise not operator (\texttt{=\~{}}) performs a bitwise not on an integral value.

\section{Primary Expressions}

\lstinputlisting[breaklines=true, firstline=105, lastline=111]{"Appendix B - Syntax.ebnf"}

A primary expression is a value or expression that is unambiguously bound. These expressions have no precedence, and in the case of identifiers and literals, form the leaf nodes of expressions.

\subsection{Identifiers}

Scoped identifiers and identifiers name a value, and produce that value as an assignable value.

\subsection{Literals}

\lstinputlisting[breaklines=true, firstline=118, lastline=128]{"Appendix B - Syntax.ebnf"}

Literals represent a constant value, either of some type, or of an aggregate initializer. Integer literals may be signed or unsigned. Integer literals are of the smallest type capable of containing their value, preferring unsigned types over signed types. A positive integer literal may be forced into being of a signed type by prefixing it with \texttt{+}.

\subsection{Cast Expressions}

A cast converts the expression to the listed type. See Appendix E - Castability for the rules and actions taken.

\subsection{Sizeof Expressions}

A size-of expression calculates the size of a type, or the size of an expression, both producing an unsigned long value. Additionally, if an expression is involved in the query, it will not be evaluated.

\end{document}
