\documentclass[letterpaper,12pt]{book}

\usepackage{indentfirst}
\usepackage[margin=1in]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{listings}
\usepackage{verbatim}
\usepackage{longtable}

% Don't put two spaces after a period
\frenchspacing

\begin{document}
\title{The T Programming Language}
\author{Justin Hu}
\maketitle
\tableofcontents

\part{Language}

\chapter{Introduction}

This document specifies the syntax and semantics of the T programming language, especially for the implementation of the reference compiler for the language. T is a systems oriented, module-based programming language. The language is statically-typed, with neither classes nor a garbage collector. Conceptually, a T program consists of a set of modules, each module exposing some public interface. An implementation of T takes in the declaration files of the used modules, and code files or linkable files (distinguished in some manner\footnote{\textbf{Reference compiler behaviour}: the reference compiler distinguishes between declaration and code files using filename extensions. Declaration files have a .td extension, while code files have a .tc extension.}), each of which implement the interface for some module, and produces an executable. This executable may then be run, in some environment, to produce some sequence of effects.

\section{Copyright}

Copyright 2019-2021 Justin Hu. This work and all of its appendices are licensed under the Creative Commons Attribution-ShareAlike 4.0 International License. To view a copy of this license, visit \url{http://creativecommons.org/licenses/by-sa/4.0/}.

\section{Compiler Structure}

A T program is translated into an executable in several phases. Since the T grammar is not context free, it is necessary to make multiple passes over the same file. These phases are considered distinct and necessary, and are expected to be present in all compiler implementations. At any point during this process, if a requirement of the standard is violated, a diagnostic message is issued, and translation may halt.

\begin{enumerate}
	\item \textbf{Lexing}: each declaration and code file is split into a sequence of tokens.

	\item \textbf{Parsing}: the sequence of tokens is parsed into an abstract syntax tree. The parse tree produced depends on the interface of the imported modules, as well as the name of declarations contained in the current module, including those declared after the current point in time in the import or file scope, this phase is split into three parts.
	\begin{enumerate}
		\item Every import or file scope declaration is parsed, but function bodies remain unparsed.
		
		\item Each file scope declaration and import is inspected, and the details for the identifiers introduced are recorded. What an identifier at top level references is resolved at this point.
		
		\item Each unparsed function body is then parsed using the information from the first and second pass, while simultaneously, details about any declarations are recorded. What an identifier references is resolved at this point.
	\end{enumerate}

	\item \textbf{Typechecking}: the program is checked for static type consistency and correctness.
	
	\item \textbf{Translation}: each code module is translated into a linkable form. This is usually an object code file. The reference compiler translates in several steps.
	\begin{enumerate}
		\item \textbf{Source Code Optimization}: optimizations are performed on the source code's abstract syntax tree. Currently, no optimizations at this level are performed.
		
		\item \textbf{Translation to IR}: each code module is translated into a three-address code form intermediate representation. This translation is independent of the target environment.
		
		\item \textbf{IR Optimization}: optimizations are performed on the intermediate representation. Currently, no optimizations at this level are performed.
		
		\item \textbf{Assembly Generation}: each code module (currently in an intermediate representation) is translated to architecture and environment-specific assembly code. This assembly code, however, does not yet have its stack frames laid out or its register usage resolved.
		
		\item \textbf{Assembly Optimization (part 1)}: optimizations are performed on the register-independent assembly. Currently, no optimizations at this level are performed.
		
		\item \textbf{Register Allocation}: the register usage for each function is resolved, and stack frames are laid out.
		
		\item \textbf{Assembly Optimization (part 2)}: optimizations are performed on the penultimate assembly code. Currently, no optimizations at this level are performed.
		
		\item \textbf{Assembling}: the generated assembly code is assembled into a linkable form. In the reference compiler, this is handled externally by the system assembler. (In Linux, this is the command \texttt{as}.)
	\end{enumerate}
	
	\item \textbf{Linking (optional)}: the generated and supplied are linked into an executable program, or into a library. This step is optional if the user wants to produce several object files. In the reference compiler, this is handled externally by the system linker or object-file archiver. (In Linux, these are the commands \texttt{ld} or \texttt{ar}.)
\end{enumerate}

\section{Environment}

A T program is compiled for one or more execution environments, in some translation environment. These environments do not have to be the same. The translation environment must be capable of providing files to the compiler, and must be capable of providing diagnostic messages to the user. The execution environment must be capable of starting execution by calling the main function, and providing the appropriate command line arguments. The environment will be affected by the program through side effects. These side effects must be visible according to the defined semantics. The execution environment must also be capable of handing the return value from the main function. Additionally, the environment must be capable of supporting the implementation and side effects of any standard library modules imported.

\subsection{Character Sets}

In addition to the general requirements above, the translation environment has a character set. This character set must be able to represent at least the printable (alphanumeric, symbols) ASCII characters, the space, and the newline\footnote{\textbf{Reference compiler behaviour}: the reference compiler treats ASCII as its source character set. It defines newline as either the ASCII line feed, the ASCII carriage return, or the ASCII carriage return followed by the ASCII line feed.}. Almost all operating systems provide this environment. The execution environment has its own, possibly distinct character set. There are no requirements on what this character set contains. For the most part, that character set is Unicode.

\chapter{Lexicon}

A source file consists of a sequence of characters. The lexing phase splits these into tokens based on the lexical syntax, and translates magic tokens into literal values. The lexical syntax is strict maximal munch. A source file is described by the EBNF given in Appendix A - Lexicon. The source file must conform to this syntax, or else a diagnostic message must be issued.

\section{Magic Tokens}

As noted in Appendix A, there are three magic tokens. Magic tokens are literal values computed during lexing. The values of these magic tokens are specified below.

\begin{itemize}
	\item \texttt{\_\_FILE\_\_}: this token is replaced with a string literal containing the name of the file being processed.
	
	\item \texttt{\_\_LINE\_\_}: this token is replaced with an unsigned integer literal containing the current line in the file being processed.
	
	\item \texttt{\_\_VERSION\_\_}: this token is replaced with a string literal containing the compiler version string. This string does not have any particular format, but is human-readable.
\end{itemize}

\chapter{Syntax}

A source file, once converted into a sequence of tokens, is then converted into a tree of tokens. The provided grammar is context sensitive, and requires at least two passes to parse, since there are disambiguation rules depending on information about the declaration site of a token. However, other than the disambiguation rules, the grammar is capable of LL(1) parsing. As with the lexing phase, any deviations from the grammar must result in a diagnostic message being issued.

The grammar for a file, without disambiguation rules, is given in Appendix B - Syntax. This grammar uses the definitions for tokens given in the lexicon.

\section{Disambiguation}

The above grammar is intended to contain two ambiguities that prevent it from being an LL(1) context free grammar:

\begin{enumerate}

	\item It is not possible to determine if an encountered identifier or scoped identifier starts a variable declaration statement or if it starts an expression (in some cases it is impossible to determine if an encountered statement is a variable declaration statement or an expression statement). As such, the parser must determine if the encountered identifier or scoped identifier is a type, and if it is a type, parse a variable declaration statement.
	
	\item There is no difference between a variable declaration and a variable definition without initialization. Contextually, variable declarations may only exist in declaration files, and variable definitions may only exist in code files.
\end{enumerate}

\section{Additional Context Requirements}

In addition to the restrictions placed by the grammar above:
\begin{itemize}
	\item no function definitions may exist within a declaration file,
	\item no function declaration may exist within a code file,
	\item no break statement may exist unless in the body of a loop or switch,
	\item no continue may exist unless in the body of a loop,
	\item no switch statement may contain more than one default case.
\end{itemize}

If a source file violates any of these requirements, a diagnostic message must be issued.

\chapter{Modules}

In T, a program is comprised of a series of modules, linked together. A module is described by its declaration file and its implementation. This implementation may be a code file, or a linkable file that contains the translation of a code file. Modules have an optional one-to-one correspondence with declaration files, and a one-to-many correspondence with code files. A translation including a linkable file shall be equivalent to one involving the original code files if no diagnostic messages would have been issued for the original code files. A module contains a set of declarations and a set of definitions.

It is possible to have a module with one declaration file or a module with no declaration file. A module with no declaration file cannot be imported by any other module, but no other module may have the same name as the module without a declaration file.

\section{Scopes}

Scopes are a mechanism to control the visibility of identifiers. A scope is a container for identifiers and other scopes. All identifiers immediately within a scope must be unique. Identifiers from containing scopes are shadowed by identifiers in the current scope, and identifiers from contained scopes are not visible. A file defines two scopes: the import scope, and the file scope. The file scope resides within the import scope, and in code files, automatically contains the identifiers declared in its corresponding declaration file (if any), as a plain identifier and as a scoped identifier. Other ways of starting a scope are discussed alongside the relevant syntactic constructs. Normally, identifiers in a scope are only visible after they are declared, but within a file scope, identifiers are visible throughout the whole scope.\footnote{The ordering and extent of identifiers within the scope is irrelevant for import scopes, since there is no possibility of using anything imported in the middle of the import list.}

\subsection{Imports}

Modules may import other modules (and may not import themselves). This means the identifiers from the module are made visible in the importing module's import scope, both as a scoped identifier consisting of the imported module name combined with the imported identifier in a scope resolution operator, and as the plain identifier. If two identifiers collide in the import scope as plain identifiers, neither is imported as a plain identifier. If there is a collision between the scoped identifiers, then a diagnostic is to be issued\footnote{This is to make the imported identifiers visible in at least one way, but there exists the possibility of a collision between scoped identifiers - if module \texttt{foo} has an enumeration called \texttt{bar} with an element \texttt{baz}, then the module \texttt{foo::bar} with an identifier \texttt{bar} would collide. Since the modules sharing a prefix are, to humans, part of the same library, the potential for such a collision is considered as bad code style on the part of the library authors.}.

\subsection{Opaque Type Declarations}

The first exception to the requirement that no identifiers in the same scope have the same name is when dealing with opaque type declarations (see \ref{section:Opaque Type Declarations}), which may be redefined only if the opaque type was introduced to the scope from the implicit import, or if the opaque type was introduced to the scope previous to the redefinition, and the redefinition is in the current scope.

\subsection{Variable and Function Definitions}

The second exception to the requirement that no identifiers in the same scope have the same name is when dealing with already-declared variables and functions. An already-existing variable may have its identifier reintroduced in a definition if and only if the previously existing binding was a declaration and the types of the variables are the same. An already-existing function may have its identifier reintroduced in a definition if and only if the previously existing binding was a declaration and the function signature is the same.

\section{Module Header}

Each module begins with a module line, that sets the name of the module. Module names are completely independent of file name. If a code file and a declaration file share this name, the code file is considered implementation for the declaration file. After the module line, each file has a list of modules that it imports into its import scope. This module line may not be a reserved identifier. Reserved identifiers may be used by the language implementation. A reserved identifier is any identifier that starts with two underscores. This includes cases where the reserved identifier is part of a larger scoped identifier that does not start with two underscores.

\section{Module Body}

A module body consists of either a set of declarations (for declaration files), or a set of declarations and definitions (for code files). In either case, an empty set is permissible.

\subsection{Declaration Files}

In declaration files, the set of declarations is the public interface for the module. Any code file importing the declaration file will have these identifiers available in the import scope, and any code file will have these identifiers available in the file scope.

\subsection{Code Files}

In a code file, declarations are not visible outside of the file. However, definitions for the declarations in the module may be supplied. Definitions may only be supplied in a code file. A definition for an identifier must define that identifier. If the code file implements a declaration file, then all identifiers within the declaration file are imported into the file scope for the code file. As an example, if there are three files, \texttt{foo.tc}, \texttt{foo.td}, \texttt{bar.td}, part of modules \texttt{foo}, \texttt{foo}, and \texttt{bar}, and both \texttt{foo.td} and \texttt{bar.td} declare the existence of the identifier \texttt{baz}, if \texttt{foo.tc} imports \texttt{bar}, it may use \texttt{baz} or \texttt{foo::baz} to refer to the \texttt{baz} from \texttt{foo.td}, and may only use \texttt{bar::baz} to refer to the \texttt{baz} from \texttt{bar.td}. This does not, however, grant any code file implementing some module additional access beyond that specified in the declaration file to the contents of any other code file implementing the same module.

\chapter{Types}

T is a statically typed language. This means that every variable has a type associated with it, and every function has a signature associated with it, and that these types and signatures are known and checked when a module is compiled. Types determine the semantics of operations on a value of that type.

\section{Basic Data Types}

T has several basic data types, listed below. These types are named in their corresponding keyword. The execution environment must be capable of supporting all data types listed below, or else the execution environment is considered non-standard. It is required for a compiler to issue a diagnostic message if compiling to a non-standard environment when encountering an unsupported type.

\begin{itemize}
	\item \texttt{void}: indicates a value of no type. This type is only used to construct other types, and is not valid on its own. This type has a size of one byte.
	
	\item \texttt{ubyte}: an unsigned integral value, one byte wide. It is assumed that bytes contain eight bits.
	
	\item \texttt{byte}: a 2's complement signed integral value, one byte wide.
	
	\item \texttt{char}: an unsigned integral value of sufficient width to contain one byte, and the narrowest character(s) within the execution environment's character set\footnote{Generally, this is one byte wide on Unicode systems.}.
	
	\item \texttt{ushort}: an unsigned integral value, two bytes wide.
	
	\item \texttt{short}: an 2's complement signed integral value, two bytes wide.
	
	\item \texttt{ushort}: an unsigned integral value, two bytes wide.
	
	\item \texttt{short}: an 2's complement signed integral value, two bytes wide.
	
	\item \texttt{uint}: an unsigned integral value, four bytes wide.
	
	\item \texttt{int}: an 2's complement signed integral value, four bytes wide.
	
	\item \texttt{wchar}: an unsigned integral value of sufficient width to contain the widest character(s) within the execution environment's character set\footnote{Generally, this is four bytes wide on Unicode systems.}.
	
	\item \texttt{ulong}: an unsigned integral value, eight bytes wide.
	
	\item \texttt{long}: an 2's complement signed integral value, eight bytes wide.
	
	\item \texttt{float}: an IEEE 754 binary32 floating point number.
	
	\item \texttt{double}: an IEEE 754 binary64 floating point number.
	
	\item \texttt{bool}: a boolean value. This type has a size of one byte, and stores either \texttt{true} or \texttt{false}. The representation of \texttt{true} shall be the integral value one, and the representation of \texttt{false} shall be the integral value zero.
\end{itemize}

\section{Defined Data Types}

There are several defined data types. These need to be declared to exist, and are given a name.

\begin{itemize}
	\item \texttt{struct}: this keyword introduces a structure type. A structure type consists of a number of fields, each having its own type. A structure is a collection of values of the given type, in the given order, and treated as one unit. Structures are not necessarily sequential in memory, as there may be padding inserted between fields to align fields for the execution environment. The address of a structure type value is the same as the address of the first element.
	
	\item \texttt{union}: this keyword introduces a union type. A union type represents a value of one of the union option types. Union types will reinterpret the given value if accessed through a non-active member. This reinterpretation is a direct reinterpretation of raw memory. A union type has the size of the largest element, and is padded to the largest padding required for the element. The address of a union type value is the same as the address of the contained value.
	
	\item \texttt{enum}: this keyword introduces an enumeration. An enumeration is a set of signed integral constants. These integral constants may take any value, but are sequentially valued, starting from zero, unless overridden (\texttt{"=", extended\_int\_literal}). When overridden, subsequent entries continue the sequential numbering from the overridden entry. If the overriding of sequential numbering causes a collision between two identifiers, then a diagnostic message must be issued.
	
	\item \texttt{typedef}: this keyword introduces a type alias. A type alias is a name for a type, usually a derived type. A type alias is treated as a new, unique, fundamental data type, meaning that a type alias value may not be treated as if it were its unaliased type. However, a type alias value may be converted into the unaliased type with a cast expression.
\end{itemize}

\section{Derived Data Types}

Any data type may form the base of a derived data type.

\begin{itemize}
	\item \textbf{Constants}: by appending \texttt{const} to a type, a type may be turned into a constant type. A value of a constant type may not be written to directly. If a constant value is written to, a diagnostic message must be issued. If a constant value is written to indirectly (e.g. through a casted pointer), undefined behaviour results, and no diagnostic message is required. The ordering of \texttt{const} and \texttt{volatile} in a declaration is irrelevant. A void base type is not allowed unless the type will form a pointer.
	
	\item \textbf{Volatiles}: by appending \texttt{volatile} to a type, a type may be turned into a volatile type. Reads and writes from and to a value of volatile type are considered side effects, and must be sequenced. The ordering of \texttt{const} and \texttt{volatile} in a declaration is irrelevant. A similar to \texttt{const} void base type is not allowed unless the type will form a pointer.
	
	\item \textbf{Arrays}: by appending a positive or unsigned extended integral constant in square brackets, a type is turned into an array of that many items. An array is guaranteed to be contiguous in memory, such that by adding (without pointer arithmetic, i.e. on the raw integer address) the size of an element, to the address of an element, you get the address of the next element. Arrays of void are not allowed, not even if they form the base of a pointer, nor are zero-length arrays.
	
	\item \textbf{Pointers}: by appending \texttt{*} to a type, a type is turned into a pointer to that type. Pointers hold an unsigned integer (width determined by the execution environment) that represents the location in memory. A void base type is allowed.
	
	\item \textbf{Function Pointers}: by appending a comma separated list of types enclosed in parentheses, with optional and ignored names, a type is turned into a function pointer to a function returning that type (which may be void), and taking the list of types as arguments. Function pointers also hold an unsigned integer (width determined by the execution environment) that represents the location in memory.
	
	\item \textbf{Aggregate Initializers}: an aggregate initialzer type cannot be explicitly formed, but it is the type of an aggregate initializer expression. An aggregate initializer's type is the product of the types of its literals.
\end{itemize}

Data types which are modified with \texttt{const} or \texttt{volatile} at top level are said to be CV-qualfied. A data type is as least as CV qualified as another type if the first type has all of the qualifiers the second type has.

\section{Type Conversions}

A value of one type can be converted into a value of another type in one of two ways - implicitly or explicitly. Syntactically, implcit conversions happen without the program needing to specify a type to convert to, or to explicitly state that a conversion is happening.

\subsection{Implicit Conversions}\label{subsection:Implicit Conversions}

A value of one type may be implicitly converted to a value of another type when, ignoring CV-qualfication, any of the following conditions are met.

\begin{enumerate}
	\item Both types are exactly the same. No conversion is performed, and the value is directly copied.
	
	\item The converted-from type is any integral type and the converted-to type is a float or a double. An integral-to-float or integral-to-double conversion (as appropriate) will be performed.
	
	\item The converted-from type is a float and the converted-to type is a double. A float-to-double conversion will be performed.
	
	\item The converted-from type is an unsigned integral type, the converted-to type is an integral type, and the converted-to type is wider than the converted-from type. An appropriate zero-extend is performed.
	
	\item The converted-from type is a signed integral type, the converted-to type is a signed integral type, and the converted-to type is wider than the converted-from type. An appropriate sign-extend is performed.
	
	\item The converted-from type is a char and the converted-to type is a wide character. A character-set appropriate widening is performed.

	\item The converted-from type is an aggregate initializer, the converted-to type is a structure type, and the elements of the aggregate initializer correspond, in order, to fields of the structure whose type the element's type can be implicitly to. The resulting structure is as if it had been elementwise converted from the aggregate initializer.

	\item The converted-from type is an aggregate initializer, the converted-to type is an array, and the elements of the aggregate initializer correspond, in order, to elements of the array whose type the element's type can be implicitly converted to. The resulting structure is as if it had been elementwise converted from the aggregate initializer.

	\item The converted-from type is a pointer, the converted-to type is a pointer, the converted-to type's base type is at least as CV-qualified as the converted-to type, and, for the base types (ignoring CV-qualification) any of the following conditions are met.\label{item:Pointer Rule}
	\begin{enumerate}
		\item Both base types are exactly the same.
		
		\item The converted-from type's base type is void.
		
		\item The converted-to type's base type is void.
		
		\item Both base types are pointers and the pointer-conversion rule (rule \ref{item:Pointer Rule}) is satisfied.
	\end{enumerate}
	
	Regardless, no conversion is performed, and the value is directly copied.
	
	\item The converted-from type is an array, the converted-to type is a pointer, and the base type of the pointer is at least as CV-qualified as the base type of the array, and, for the base types (ignoring CV-qualification) any of the following conditions are met:
	\begin{enumerate}
		\item Both base types are exactly the same.
		
		\item The pointer's base type is void.
	\end{enumerate}
\end{enumerate}

\subsection{Explicit Conversions}\label{subsection:Explicit Conversions}

A value of one type may be explicitly converted to a value of another type when, ignoring CV-qualfication, any of the following conditions are met.

\begin{enumerate}
	\item The converted-from type could be implicitly converted into the converted-to type. The same conversion as the implicit conversion happens.
	
	\item The converted-from type and converted-to type are both numeric or characters. The appropriate integral-to-floating, truncation, or extension is performed.
	
	\item The converted-from type is a pointer or function pointer and the converted-to type is any integral type, or vice versa, or both are pointers. The pointer is converted as if it were an unsigned long.
	
	\item One type is a type alias of another type. This rules is not applied transitively - if \texttt{A} is an alias of \texttt{B}, which is an alias for \texttt{C}, \texttt{A} cannot be explicitly converted into \texttt{C} in one step.
	
	\item The converted-from type is a boolean and the converted-to type is any integral or floating-point type. The converted-to value is one if the boolean is true and zero if the boolean is false.
	
	\item The converted-from type is any integral, floating-point, or pointer type and the converted-to type is a boolean. The converted-to value is true if the converted-from value is not zero (or null, as appropriate), and false otherwise.
	
	\item The converted-from type is a floating point or integral type, and the converted-to type is an enumeration. The converted-from type is converted to an integer with the same size and signedness as the converted-to enumeration's underlying type.
	
	\item The converted-from type is an enumeration and the converted-to type is a floating point or integral type. The converted-from type is converted to the converted-to type using the enumeration's underlying type.
\end{enumerate}

\subsection{Arithmetic Type Merging}\label{subsection:Arithmetic Type Merging}

When two integral or floating point values are operated on by an arithmetic operator, they are first converted into a common type, using the following rules, and ignoring CV-qualification. The rules take precedence from top to bottom.

\begin{enumerate}
	\item If one type is a double, the common type is a double.
	
	\item If one type is a float, the common type is a float.
	
	\item If both types are integral, the common type is the integral type that can hold all values from both the left and right hand sides. If no such type exists, then the two types cannot be combined in an arithmetic expression.
\end{enumerate}

\subsection{Ternary Type Merging}\label{subsection:Ternary Type Merging}

When two values are the consequent and the alternative of a ternary operator, they are first converted into a common type. The rules take precedence from top to bottom.

\begin{enumerate}
	\item The result of two CV-qualified types is the union of the qualifications applied to the result of recursively merging their base types.\label{item:Ternary Same Type}
	
	\item If both types are the same, the common type is the same as both types.
	
	\item If both types are numeric, the common type is the one that results from \ref{subsection:Arithmetic Type Merging}.
	
	\item If both types are character types, the common type is a wide character. (Note that the case where both are characters is covered by rule \ref{item:Ternary Same Type}.
	
	\item If both types are pointers, then (in precedence from top to bottom):
	\begin{enumerate}
		\item The result of two CV-qualfied base types is the union of the qualifications applied to the result of recursively merging their base types.
		
		\item Two identical base types result in the same base type.
		
		\item Two different base types result in a void base type.
	\end{enumerate}
\end{enumerate}

\subsection{Comparison Type Merging}\label{subsection:Comparison Type Merging}

When two values are involved in an equality or other comparison, they are sometimes converted into a common type. Since comparisons ignore CV-qualfication, the CV-qualification of the two values is also ignored. The following rules take precedence from top to bottom.

\begin{enumerate}
	\item Character and numeric types are merged as if in a ternary.
	
	\item Booleans and enumerations may only be compared with identical types, and are compared as themselves.
	
	\item Pointers may be compared with any other pointer if one can be implicitly converted into another, and are compared as if void pointers.
\end{enumerate}

\chapter{Declarations}

\lstinputlisting[breaklines=true, firstline=9, lastline=16]{"Appendix B - Syntax.ebnf"}

Declarations state the existence of a type, function, or variable in the current module. For type declarations, they may also serve as the definition of a type. Conceptually, a declaration is all that is required to use the declared entity, and the user need not be aware of the definition. However, for non-opaque types, it is necessary to know the definition of the type to use it completely - it is necessary to know the size of a type to declare it on the stack. For opaque types, it is not necessary to have that additional information, so both kinds of declarations - complete and opaque - are considered declarations.

The identifier in a declaration may not be a reserved identifier. Reserved identifiers may be used by the language implementation. Any identifier that starts with two underscores is considered reserved.

\section{Function Declarations}

\lstinputlisting[breaklines=true, firstline=21, lastline=21]{"Appendix B - Syntax.ebnf"}

A function declaration declares the existence of the function, having the name in the first identifier, and provides the interface to call the function and get a return value. The parameter names are not significant, and may be different from the names used in the function definition. The return type and formal parameter types must be complete types, except that a return value of \texttt{void} indicates that the function does not return any value.

\subsection{Main Functions}\label{subsection:Main Functions}

Any function named 'main' is considered a main function. The main function does not need to be declared. Only one main function may be declared or defined per executable, but it is irrelevant in which module the main function is declared or defined. A main function may have zero or two parameters. If there are two parameters, the first parameter must be a \texttt{uint} and the second parameter must be a pointer to pointer to \texttt{char}. A diagnostic must be issued if the main function does not have the correct parameter count or types. The first parameter will hold the number of command line arguments and the second will hold either \texttt{null}, if there are no command line arguments, or a pointer to a list of null-terminated character strings listing the command line arguments. If there are any command line arguments, then the zeroth represents the name of the program, while the remaining are the command line arguments. Additionally, the main function must return an \texttt{int}. A diagnostic must be issued if the return type of main is not \texttt{int}.

\section{Variable Declarations}

\lstinputlisting[breaklines=true, firstline=22, lastline=22]{"Appendix B - Syntax.ebnf"}

A variable declaration declares the existence of a global variable. Variable declarations may use an incomplete type (the corresponding definition must not use an incomplete type). The comma separated list of identifiers lists out the names declared as a variable.

\section{Opaque Type Declarations}\label{section:Opaque Type Declarations}

\lstinputlisting[breaklines=true, firstline=23, lastline=23]{"Appendix B - Syntax.ebnf"}

An opaque type declaration declares the existence of a user-defined type (structure, union, enumeration, or alias). Other than the existence of that type as a user-defined type, and the name, nothing else is specified.

When redefined in a code file when it occurs in a declaration file, previous references to the opaque type are considered equivalent to a reference to the overriding type. When redefined in a function when it occurs in the same scope, previous references to the opaque type are also considered equivalent to a reference to the overriding type. Even though the type was redefined, the opaque type cannot be used in any way that would require more information than the existence and name of the type.

\section{Struct Type Declarations}

\lstinputlisting[breaklines=true, firstline=24, lastline=24]{"Appendix B - Syntax.ebnf"}

A structure type declaration defines a structure type. Each variable declaration has a set of identifiers that it declares, and each of those identifiers is a field, with the type corresponding to the type of the variable declaration.

\section{Union Type Declarations}

\lstinputlisting[breaklines=true, firstline=25, lastline=25]{"Appendix B - Syntax.ebnf"}

A union type declaration defines a union type. Each variable declaration has a set of identifiers that it declares, and each of those identifiers is an option for the union, with the type corresponding to the type of the variable declaration.

\section{Enum Type Declaration}

\lstinputlisting[breaklines=true, firstline=26, lastline=26]{"Appendix B - Syntax.ebnf"}

An enumeration declaration defines an enumeration type. Each identifier is a separate enumeration constant, with either an automatically set or manually set value. Numbering of constants is sequential from the previous manually set value, or zero, if no manually set value has been encountered.

\section{Typedef Declaration}

\lstinputlisting[breaklines=true, firstline=27, lastline=27]{"Appendix B - Syntax.ebnf"}

A typedef declaration introduces a type alias. This type alias is treated as if it were an atomic type, disallowing any decomposition. However, the a value of this type may be cast into the original type, allowing for decomposition after a cast.

\chapter{Definitions}

\lstinputlisting[breaklines=true, firstline=6, lastline=8]{"Appendix B - Syntax.ebnf"}

Definitions provide the value of a declared variable or function. Only code files may contain definitions, and in a code file, no variable declarations are allowed. Within a code file, it is permissible to have a definition without an attached declaration. If there is no corresponding declaration, or if the declaration is in the same code file, then the declared entity is not visible to other modules.

\section{Function Definitions}

\lstinputlisting[breaklines=true, firstline=18, lastline=18]{"Appendix B - Syntax.ebnf"}

A function definition specifies the code for a function, in the compound statement. Additionally, the definition introduces two scopes - one from the compound statement, the function body, and the second, a scope containing the formal parameters. The formal parameter scope contains the function body scope. Any function named 'main' is considered a main function, and is subject to the limits described in \ref{subsection:Main Functions}.

\section{Variable Definitions}

\lstinputlisting[breaklines=true, firstline=19, lastline=19]{"Appendix B - Syntax.ebnf"}

A variable definition creates a variable, and optionally initializes the variable. If the variable is not initialized, then its value is undefined. Access to uninitialized variables is considered undefined behaviour.

A variable may only be initialized by a value if the value is implcitly convertable to the type of the variable.

\chapter{Statements}

\lstinputlisting[breaklines=true, firstline=29, lastline=47]{"Appendix B - Syntax.ebnf"}

Statements are units of execution that generally involve either side effects or flow control. Additionally, a statement may be a type or variable definition. These types or variables exist only within the containing scope.

\section{Compound Statements}

\lstinputlisting[breaklines=true, firstline=49, lastline=49]{"Appendix B - Syntax.ebnf"}

The compound statement introduces a scope, and additionally bundles a set of statements into one statement.

\section{If Statements}

\lstinputlisting[breaklines=true, firstline=50, lastline=50]{"Appendix B - Syntax.ebnf"}

An if statement dynamically chooses between the execution of two statements, or between executing a statement or not executing a statement. There are two forms to the if statement: the first form where there is no else, and the statement executes the statement if and only if the condition expression is true. The second form is when there is an else. The if statement will execute the first statement if and only if the condition is true, and the second statement otherwise.

The construct known as an else-if is a special case of the else statement: an else-if is just an if statement as the only statement in the else of the first if statement. There is no need for additional syntactic support for the else-if construct.

Finally, both the consequent and the optional alternative statements of an if statement introduce their own scopes. Thus it is valid to declare a variable in the consequent statement of an if statement, but that variable will not be visible outside of the if statement.

The condition must be a value implicitly convertable to boolean.

\section{While Loop Statements}

\lstinputlisting[breaklines=true, firstline=51, lastline=51]{"Appendix B - Syntax.ebnf"}

A while loop statement repeatedly executes the statement, checking the condition beforehand, and leaving the loop without executing the statement if and only if the expression is false. The loop body introduces a scope.

The condition must be a value implicitly convertable to boolean.

\section{Do-While Loop Statements}

\lstinputlisting[breaklines=true, firstline=52, lastline=52]{"Appendix B - Syntax.ebnf"}

A do-while loop statement repeatedly executes the statement, checking the condition afterwards, and leaving the loop if and only if the expression is false
\footnote{Unlike C, the do-while loop does not expect a semicolon after the while.}. The loop body introduces a scope.

The condition must be a value implicitly convertable to boolean.

\section{For Loop Statements}

\lstinputlisting[breaklines=true, firstline=53, lastline=53]{"Appendix B - Syntax.ebnf"}

The for loop statement introduces a scope, and within that scope, the variable declaration statement resides. If the initializer is an expression, then the expression is evaluated for side-effect. Next, before each iteration of the loop, the condition is checked, then the loop body runs, then the increment expression is evaluated for side effects. Execution returns to checking for the condition. If the condition is false, the loop ends, and the increment is not run. Additionally, a continue statement will only jump to the increment expression - i.e. the end of the loop body. The loop body also introduces a scope.

The condition must be a value implicitly convertable to boolean, and the initializer and increment must obey their type rules.

\section{Switch Statements}

\lstinputlisting[breaklines=true, linerange={54-54, 61-62}]{"Appendix B - Syntax.ebnf"}

A switch statement selects between several possible cases. The expression is evaluated, and it must be an integral expression. Then, the matching case is selected, and the matching statement is executed. Then, unless execution hits a break, execution proceeds down the following cases. If no case is matched, then the default and its statement is executed, and execution of the switch continues down the remaining cases. It is an error to have multiple cases with the same value, or multiple default cases. Additionally, despite the curly braces, the switch itself does not introduce a scope.

The condition must be an integral, character, or enumeraton type. Additionally, all case values must be implicitly convertable to the type of the condition.

\section{Break Statements}

\lstinputlisting[breaklines=true, firstline=55, lastline=55]{"Appendix B - Syntax.ebnf"}

A break statement will leave a loop or a switch statement. The break statement jumps to the first statement after the end of the loop or switch.

\section{Continue Statements}

\lstinputlisting[breaklines=true, firstline=56, lastline=56]{"Appendix B - Syntax.ebnf"}

A continue statement will jump to the end of the body of a loop. Note that in a for loop, the continue statement will not skip over the increment, as that comes just after the body.

\section{Return Statements}

\lstinputlisting[breaklines=true, firstline=57, lastline=57]{"Appendix B - Syntax.ebnf"}

A return statement returns from the current function. If an expression is provided, it must match the return type of the function, and the value of the expression will be the returned value. If a value is not provided, then the function must be void, or the value must have been provided in some other way - almost certainly through inline assembly.

The returned value must be implicitly convertable to the return type of the function.

\section{Assembly Statements}

\lstinputlisting[breaklines=true, firstline=58, lastline=58]{"Appendix B - Syntax.ebnf"}

An assembly statement inserts the assembly code into the generated assembly. The string literal respects escape codes, but is otherwise inserted verbatim. It is the responsibility of the user to write valid assembly code and to ensure that said assembly code will interoperate with generated assembly code.

\section{Variable Declaration Statements}\label{section:Variable Declaration Statements}

\lstinputlisting[breaklines=true, firstline=59, lastline=59]{"Appendix B - Syntax.ebnf"}

A variable declaration statement creates a variable, and optionally initializes the variable with an expression. If it is not initialized, then its value is undefined. The variable exists in the enclosing scope.

The value a variable is initialized with must be implicitly convertable to the variable's type.

\section{Expression Statement}

\lstinputlisting[breaklines=true, firstline=60, lastline=60]{"Appendix B - Syntax.ebnf"}

The expression statement is an expression followed by a semicolon. The expression is evaluated for side-effects, and only side-effects.

\section{Empty Statement}

The empty statement is a single semicolon. It represents doing nothing, and is used only as a placeholder.

\chapter{Expressions}

Expressions perform computations and produce values. Generally, an expression involves an operator and one or more sub-expressions. Below is a summary of the operators, their associativities, and their precedences (lower precedence numbers bind less tightly). This table is derived from the grammar.

\begin{longtable}{|c|c|c|c|}
\hline
\textbf{Operator} & \textbf{Description} & \textbf{Associativity} & \textbf{Precedence}\\
\hline
\texttt{,} & sequencing & left to right & 1\\
\hline
\texttt{=} & assignment & right to left & 2\\
\hline
\texttt{*=} & compound multiplication-assignment & right to left & 2\\
\hline
\texttt{/=} & compound division-assignment & right to left & 2\\
\hline
\texttt{\%=} & compound modulo-assignment & right to left & 2\\
\hline
\texttt{+=} & compound addition-assignment & right to left & 2\\
\hline
\texttt{-=} & compound subtraction-assignment & right to left & 2\\
\hline
\texttt{<<=} & compound left-shift-assignment & right to left & 2\\
\hline
\texttt{>>=} & compound arithmetic-right-shift-assignment & right to left & 2\\
\hline
\texttt{>>>=} & compound logical-right-shift-assignment & right to left & 2\\
\hline
\texttt{\&=} & compound bitwise-and-assignment & right to left & 2\\
\hline
\texttt{\^{}=} & compound bitwise-exclusive-or-assignment & right to left & 2\\
\hline
\texttt{|=} & compound bitwise-or-assignment & right to left & 2\\
\hline
\texttt{\&\&=} & compound logical-and-assignment & right to left & 2\\
\hline
\texttt{||=} & compound logical-or-assignment & right to left & 2\\
\hline
\texttt{?:} & ternary conditional & right to left & 3\\
\hline
\texttt{\&\&} & logical and & left to right & 4\\
\hline
\texttt{||} & logical or & left to right & 4\\
\hline
\texttt{\&} & bitwise and & left to right & 5\\
\hline
\texttt{|} & bitwise or & left to right & 5\\
\hline
\texttt{\^{}} & bitwise exclusive-or & left to right & 5\\
\hline
\texttt{==} & equality & left to right & 6\\
\hline
\texttt{!=} & inequality & left to right & 6\\
\hline
\texttt{<} & less than & left to right & 7\\
\hline
\texttt{>} & greater than & left to right & 7\\
\hline
\texttt{<=} & less than or equal to & left to right & 7\\
\hline
\texttt{>=} & greater than or equal to & left to right & 7\\
\hline
\texttt{<<} & left shift & left to right & 8\\
\hline
\texttt{>>} & arithmetic right shift & left to right & 8\\
\hline
\texttt{>>>} & logical right shift & left to right & 8\\
\hline
\texttt{+} & addition & left to right & 9\\
\hline
\texttt{-} & subtraction & left to right & 9\\
\hline
\texttt{*} & multiplication & left to right & 10\\
\hline
\texttt{/} & division & left to right & 10\\
\hline
\texttt{\%} & modulo & left to right & 10\\
\hline
\texttt{*} & dereference & right to left & 11\\
\hline
\texttt{\&} & address of & right to left & 11\\
\hline
\texttt{++} & pre-increment & right to left & 11\\
\hline
\texttt{--} & pre-decrement & right to left & 11\\
\hline
\texttt{-} & negation & right to left & 11\\
\hline
\texttt{!} & logical not & right to left & 11\\
\hline
\texttt{\~{}} & bitwise not & right to left & 11\\
\hline
\texttt{.} & member access & left to right & 12\\
\hline
\texttt{->} & pointer member access & left to right & 12\\
\hline
\texttt{()} & function call & left to right & 12\\
\hline
\texttt{[]} & array index & left to right & 12\\
\hline
\texttt{++} & post-increment & left to right & 12\\
\hline
\texttt{--} & post-decrement & left to right & 12\\
\hline
\texttt{=-} & in-place negate & left to right & 12\\
\hline
\texttt{=!} & in-place logical not & left to right & 12\\
\hline
\texttt{=\~{}} & in-place bitwise not & left to right & 12\\
\hline
\end{longtable}

\section{Operators}

Operators combine one or more expressions, and produce a value. See the above for a list of all operators and their precedences and associativities. Below is a summary of the effects of the operators:

\subsection{Sequencing Operator}

\lstinputlisting[breaklines=true, firstline=65, lastline=67]{"Appendix B - Syntax.ebnf"}

The sequencing operator (\texttt{,}), evaluates the left hand side for side-effects, and evaluates the right hand side for a value, and produces that value.

The whole expression has the same type as its right hand side, and is an lvalue if its right hand side is.

\subsection{Assignment Operators}

\lstinputlisting[breaklines=true, firstline=68, lastline=83]{"Appendix B - Syntax.ebnf"}

The plain assignment operator (\texttt{=}) evaluates the left hand side as a value to assign to, then evaluates the right hand side as a value, and assigns the result of the right hand side to the result of the left hand side.

The other assignment operators are the compound assignment operators. These evaluate the left hand side as a value to be assigned to, retrieve its value, evaluate the right hand side, perform the operation on the two values, and assign the result to the left hand side. The left hand side will only be evaluated once.

A plain assignment is only possible to a type that is not const-qualified, and to which the assigned value can be implicitly converted.

A compound assignment is only possible if the left and right hand side values could be used in the corresponding operator, and if the result of the operator is implicitly convertable to the assigned-to value.

A plain or compound assignment produces an lvalue which is the same as its left hand side, which must be an lvalue.

\subsection{Ternary Conditional Operators}

\lstinputlisting[breaklines=true, firstline=84, lastline=86]{"Appendix B - Syntax.ebnf"}

The ternary operator acts like an if statement for expressions. It evaluates the left hand side, and if and only if the left hand side is true, it will evaluate the middle expression and produce its value. Otherwise, it will evaluate the right hand expression and produce its value. Only one of the two expressions will be evaluated.

A ternary expression produces the type from merging the type of its operands according to \ref{subsection:Ternary Type Merging}. The value is an rvalue. Like an if statement, the predicate must be implicitly convertable to boolean.

\subsection{Logical Operators}

\lstinputlisting[breaklines=true, firstline=87, lastline=87]{"Appendix B - Syntax.ebnf"}

The logical and and logical or operators perform the standard boolean operation on their left and right hand sides.

A logical operator produces an rvalue boolean, and both its inputs must be implicitly convertable to boolean.

\subsection{Bitwise Operators}

\lstinputlisting[breaklines=true, firstline=88, lastline=88]{"Appendix B - Syntax.ebnf"}

The bitwise operators perform the standard operation on their left and right hand sides.

The two operands are first converted into a common type (see \ref{subsection:Arithmetic Type Merging}) before being operated on, and the common type must be integral. The result of a bitwise operator is the same as the merged type, and is an rvalue.

\subsection{Comparison Operators}

\lstinputlisting[breaklines=true, firstline=89, lastline=90]{"Appendix B - Syntax.ebnf"}

Comparisons are valid for base types can be merged in a comparison type merge, and result in an rvalue boolean.

\subsection{Shift Operators}

\lstinputlisting[breaklines=true, firstline=92, lastline=92]{"Appendix B - Syntax.ebnf"}

The left-hand-side value is bit-shifted by the number of bits given in the right-hand-side value. This value must be less than the number of bits in the left hand side value, but this is not statically enforced. In case of a left-shift operator (\texttt{<<}) or a logical-right-shift operator (\texttt{>>>}), the value is zero-filled. In case of an arithmetic-right-shift operator (\texttt{>>}), the value is sign-filled.

The left-hand side must be a signed integral type for arithmetic-right-shift oeprators, and any integral or pointer type for the other shift operators, and the right hand side must be an unsigned integral type. The result is an rvalue of the same type as the left-hand side.

\subsection{Addition Operators}

\lstinputlisting[breaklines=true, firstline=93, lastline=93]{"Appendix B - Syntax.ebnf"}

Addition and subtraction of two numeric operands performs the standard operation. Adding a pointer and an integer (in any order) or subtracting an integer from a pointer results in a new pointer after performing the standard operation, but with the integer multiplied by the size of the pointed-to type. Subtracting two pointers results in a difference which is then integer divided by the size of the pointed-to type.

Addition and subtraction both support two numeric operands, producing the arithmetic type merge of their operands. Addition supports a pointer and any integral operand (in any order). Subtraction supports a pointer on the left hand side and any integral type on the right hand side. Both of those cases produce the pointer. Subtraction also supports two pointers which, ignoring the CV-qualfication of their base types, are the same, producing the longest signed integer type possible. In any case, a rvalue is produced.

\subsection{Multiplication Operators}

\lstinputlisting[breaklines=true, firstline=94, lastline=94]{"Appendix B - Syntax.ebnf"}

Multiplication expressions perform the standard operation on any numeric values. The modulo operator performs the remainder operation - the sign of the result is the same as the sign of the left hand side.

The type after an arithmetic type merge must be numeric, and the result is a rvalue of the same type as the merged type.

\subsection{Prefix Operators}

\lstinputlisting[breaklines=true, firstline=95, lastline=103]{"Appendix B - Syntax.ebnf"}

The dereference operator (\texttt{*}) takes the expression (must be a data pointer), and produces an lvalue from that expression. The result is of the base type of the pointer.

The address-of operator (\texttt{\&}) takes the expression (must be an lvalue), and produces an address from that expression. The resulting type is a pointer whose base type is the type of the lvalue.

The pre-increment and pre-decrement operators (\texttt{++}, \texttt{--}) take the expression (must be an lvalue, and either numeric or a pointer), and if it is numeric, increments or decrements it by one, if it is a data pointer, adds or subtracts the size of the type the pointer points to. The value produced is that after the increment, and is an lvalue.

The negation operator takes the expression (must be a signed numeric value), and negates it. The resulting type remains the same, and is an rvalue.

The logical-not operator takes the expression (must be a boolean value), and negates it. Its type is unchanged, and it is an rvalue.

The bitwise-not operator takes the expression (must be an integral value), and flips each bit in the expression. Its type is unchanged, and it is an rvalue.

\subsection{Postfix Operators}

\lstinputlisting[breaklines=true, linerange={104-104, 112-112}]{"Appendix B - Syntax.ebnf"}

The member-access operator (\texttt{.}) takes a value of a type with members (structures or unions), and produces the named member. This value is assignable if the original value is assignable. The pointer member-access operator (\texttt{->}) takes a value of a pointer to a type with members, and produces the named member after dereferencing the pointer. Only the accessed member is accessed via the pointer. The produced value is always assignable. The type of this expression is the type of the member.

The function-call operator (\texttt{()}) takes a value that is either a function pointer or a function name, evaluates it, a comma separated list of assignment expressions (sequencing operators, if used, must be surrounded by parentheses), evaluated in an unspecified order, and calls the function or function pointer with the argument list. The produced type is that of the return value of the function. If the function returns void, then this must have been evaluated for side-effect only.

The array-index operator (\texttt{[]}) takes a value that is either a pointer or an array, evaluates that, and an integral index, evaluates that, and produces either that element in the array, if the value is an array, or the dereference of the sum (with pointer arithmetic as for the addition operator) of the pointer and the index. The resulting type is the same as the base type of the pointer or array, and is a lvalue if it was the result of indexing a pointer or an lvalue array.

The post-increment and post-decrement operators (\texttt{++}, \texttt{--}) produce the value, then increment it or decrement it exactly like a pre-increment or pre-decrement operator. The value is only evaluated once. The result is an rvalue.

The in-place unary operators take the value, performs the unary operation on it, stores it, and produces the original value like a post-increment or post-decrement operator. The in-place negation operator (\texttt{=-}) performs a negation on a signed numeric value, the in-place logical not operator (\texttt{=!}) performs a logical not on a boolean value, and the in-place bitwise not operator (\texttt{=\~{}}) performs a bitwise not on an integral value. In all cases, the resulting value is an rvalue.

\section{Primary Expressions}

\lstinputlisting[breaklines=true, firstline=105, lastline=111]{"Appendix B - Syntax.ebnf"}

A primary expression is a value or expression that is unambiguously bound. These expressions have no precedence, and in the case of identifiers and literals, form the leaf nodes of expressions.

\subsection{Identifiers}

Scoped identifiers and identifiers name a value, and produce that value as an lvalue.

\subsection{Literals}

\lstinputlisting[breaklines=true, firstline=118, lastline=128]{"Appendix B - Syntax.ebnf"}

Literals represent a constant value, either of some type, or of an aggregate initializer. Integer literals may be signed or unsigned. Integer literals are of the smallest type capable of containing their value, preferring unsigned types over signed types. A positive integer literal may be forced into being of a signed type by prefixing it with \texttt{+}.

\subsubsection{Escape Sequences}

A backslash followed by a sequence of characters in a character or string literal forms an escape sequence. The following escape sequences are recognized:

\begin{itemize}
	\item \texttt{\textbackslash n}: a newline
	\item \texttt{\textbackslash r}: a carriage return
	\item \texttt{\textbackslash t}: a tab
	\item \texttt{\textbackslash 0}: a null character
	\item \texttt{\textbackslash\textbackslash}: a literal backslash
	\item \texttt{\textbackslash x} \textit{hex\_digit} \textit{hex\_digit}: constructs a character from two nybbles
	\item \texttt{\textbackslash u} \textit{hex\_digit} \textit{hex\_digit} \textit{hex\_digit} \textit{hex\_digit} \textit{hex\_digit} \textit{hex\_digit} \textit{hex\_digit} \textit{hex\_digit}: constructs a wide character from eight nybbles - only valid for wchar and wstring literals
	\item \texttt{\textbackslash '}: a literal single quote - only valid for character literals
	\item \texttt{\textbackslash "}: a literal double quote - only valid for string literals
\end{itemize}

\subsection{Cast Expressions}

A cast converts the expression to the listed type. See \ref{subsection:Explicit Conversions} for rules on explicit conversions.

\subsection{Sizeof Expressions}

A size-of expression calculates the size of a type, or the size of an expression, both producing an unsigned long value. Additionally, if an expression is involved in the query, it will not be evaluated.

A size-of expression results in an rvalue ulong.

\end{document}
