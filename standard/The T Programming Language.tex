\documentclass[letterpaper,12pt]{book}

\usepackage{indentfirst}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{verbatim}

% Don't put two spaces after a period
\frenchspacing

\begin{document}
\title{The T Programming Language}
\author{Justin Hu}
\maketitle
\tableofcontents

\part{Language}

\chapter{Introduction}

This document specifies the syntax and semantics of the T programming language, specifically with respect to the implementation of the reference compiler for the language. T is a systems oriented, module-based programming language. The language is statically-typed, with neither classes nor a garbage collector. Conceptually, a T program consists of a set of modules, each module exposing some public interface. An implementation of T takes in the declaration files of the used modules, and code files or linkable files (distinguished in some manner\footnote{\textbf{Reference compiler behaviour}: the reference compiler distinguishes between declaration and code files using filename extensions. Declaration files have a .td extension, while code files have a .tc extension.}), each of which implement the interface for some module, and produces an executable. This executable may then be run, in some environment, to produce some sequence of effects.

\section{Compiler Structure}

A T program is translated into an executable in several phases. Since the T grammar is not context free, it is necessary to make multiple passes over the same file. These phases are considered distinct and necessary, and are expected to be present in all compiler implementations. At any point during this process, if a requirement of the standard is violated, a diagnostic message is issued, and translation may halt.

\begin{enumerate}
	\item \textbf{Lexing}: each declaration and code file is split into a sequence of tokens.

	\item \textbf{Parsing}: the sequence of tokens is parsed into an abstract syntax tree. The parse tree produced depends on the interface of the imported modules, as well as the name of declarations contained in the current module, including those declared after the current point in time in the import or file scope, this phase is split into two parts.
	\begin{enumerate}
		\item Every import or file scope declaration is inspected, and the declaration's name is recorded. The body of these declarations is left unparsed.
		
		\item Each unparsed body is then parsed using the information from the first pass.
	\end{enumerate}

	\item \textbf{Typechecking}: the program is checked for static type consistency and correctness. As with parsing, this phase is also split over multiple phases.
	\begin{enumerate}
		\item Each file scope declaration is inspected, and the details for the declaration are recorded.
		
		\item Each imported scope declaration is recorded in the current scope.
		
		\item Traversing through the scopes, each declaration is inspected, and the details for it are recorded. Simultaneously, each identifier is inspected, and matched to an entry.
		
		\item Finally, each expression is checked for type consistency by looking at the sub-expressions that make it up, and by looking at the details recorded for each identifier encountered.
	\end{enumerate}
	
	\item \textbf{Translation}: each code module is translated into a linkable form. This is usually an object code file. The reference compiler translates in several steps.
	\begin{enumerate}
		\item \textbf{Source Code Optimization}: optimizations are performed on the source code's abstract syntax tree. Currently, no optimizations at this level are performed.
		
		\item \textbf{Translation to IR}: each code module is translated into a three-address code form intermediate representation. This translation is independent of the target environment.
		
		\item \textbf{IR Optimization}: optimizations are performed on the intermediate representation. Currently, no optimizations at this level are performed.
		
		\item \textbf{Assembly Generation}: each code module (currently in an intermediate representation) is translated to architecture and environment-specific assembly code. This assembly code, however, does not yet have its stack frames laid out or its register usage resolved.
		
		\item \textbf{Assembly Optimization (part 1)}: optimizations are performed on the register-independent assembly. Currently, no optimizations at this level are performed.
		
		\item \textbf{Register Allocation}: the register usage for each function is resolved, and stack frames are laid out.
		
		\item \textbf{Assembly Optimization (part 2)}: optimizations are performed on the penultimate assembly code. Currently, no optimizations at this level are performed.
		
		\item \textbf{Assembling}: the generated assembly code is assembled into a linkable form. In the reference compiler, this is handled externally by the system assembler. (In Linux, this is the command \texttt{as}.)
	\end{enumerate}
	
	\item \textbf{Linking (optional)}: the generated and supplied are linked into an executable program, or into a shared library. This step is optional if the user wants to produce several object files. In the reference compiler, this is handled externally by the system linker or object-file archiver. (In Linux, these are the commands \texttt{ld} or \texttt{ar}.)
\end{enumerate}

\section{Environment}

A T program is compiled for one or more execution environments, in some translation environment. These environments do not have to be the same. The translation environment must be capable of providing files to the compiler, and must be capable of providing diagnostic messages to the user. The execution environment must be capable of starting execution by calling the main function, and providing the appropriate command line arguments. The environment will be affected by the program through side effects. These side effects must be visible according to the defined semantics. The execution environment must also be capable of handing the return value from the main function. Additionally, the environment must be capable of supporting the implementation and side effects of any standard library modules imported.

\subsection{Character Sets}

In addition to the general requirements above, the translation environment has a character set. This character set must be able to represent at least the printable (alphanumeric, symbols) ASCII characters, the space, and the newline\footnote{\textbf{Reference compiler behaviour}: the reference compiler treats ASCII as its source character set. It defines newline as either the ASCII line feed, the ASCII carriage return, or the ASCII carriage return followed by the ASCII line feed.}. Almost all operating systems provide this environment. The execution environment has its own, possibly distinct character set. There are no requirements on what this character set contains. For the most part, that character set is Unicode.

\chapter{Lexicon}

A source file consists of a sequence of characters. The lexing phase splits these into tokens based on the lexical syntax. The lexical syntax is strict maximal munch. A source file is described by the EBNF below. The source file must conform to this syntax, or else a diagnostic message must be issued.

\begin{lstlisting}[breaklines=true]
file = { [ whitespace ], token }, [ whitespace ], eof ;

whitespace = " "
           | ? newline ?
           | ? any other implementation-defined whitespace ?
           | "//", ? anything excluding newline ?, newline
           | "/*", ? anything excluding "*/", "*/"
           ;

token = keyword
      | punctuation
      | identifier
      | literal
      ;

keyword = "module" | "import" | "struct" | "union" | "enum"
        | "typedef" | "if" | "else" | "while" | "do" | "for"
        | "switch" | "case" | "default" | "break" | "continue"
        | "return" | "asm" | "cast" | "sizeof" | "true" | "false"
        | "null" | "void" | "ubyte" | "byte" | "char" | "ushort"
        | "short" | "uint" | "int" | "wchar" | "ulong" | "long"
        | "float" | "double" | "bool" | "const" | "volatile"
        ;

punctuation = ";" | "," | "(" | ")" | "[" | "]" | "{" | "}" | "."
            | "->" | "++" | "--" | "*" | "&" | "+" | "-" | "!"
            | "~" | "/" | "%" | "<<" | ">>" | ">>>" | "<=>" | "<"
            | ">" | "<=" | ">=" | "==" | "!=" | "|" | "^" | "&&"
            | "||" | "?" | ":" | "=" | "*=" | "/=" | "%=" | "+="
            | "-=" | "<<=" | ">>=" | ">>>=" | "&=" | "^=" | "|="
            | "&&=" | "||=" | "::"
            ;

identifier = ( alphabetic | "_" ), { alphabetic | digit | "_" } ;

literal = string_literal
        | char_literal
        | int_literal
        | float_literal
        | wstring_literal
        | wchar_literal
        ;
int_literal = [ "-" | "+" ], nonzero_digit, { digit }
            | "0x", hex_digit, { hex_digit }
            | "0b", binary_digit, { binary_digit }
            | "0", octal_digit, { octal_digit }
            ;
float_literal = [ "-" | "+" ], digit, { digit }, ".", digit, { digit } ;
string_literal = '"', { alphabetic | digit | symbol | escaped | escaped_double_quote | "'" }, '"' ;
char_literal = "'", ( alphabetic | digit | symbol | escaped | escaped_quote | '"' ), "'" ;
wstring_literal = '"', { alphabetic | digit | symbol | escaped | escaped_wchar | escaped_double_quote | "'" } '"w' ;
wchar_literal = "'", ( alphabetic | digit | symbol | escaped | escaped_wchar | escaped_quote | '"' ), "'w" ;

alphabetic = ? any ASCII alphabetic character ?
           | ? any implementation-defined alphabetic characters ?
           ;
nonzero_digit = "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9" ;
digit = "0"
      | nonzero_digit
      ;
symbol = ? any ASCII symbol plus space ?
       | ? any implementation-defined symbols or spaces ?
       ;
hex_digit = digit
          | "a" | "b" | "c" | "d" | "e" | "f"
          | "A" | "B" | "C" | "D" | "E" | "F"
          ;
binary_digit = "0" | "1" ;
octal_digit = "0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" ;
escaped = "\n" | "\r" | "\t" | "\0" | "\\" | "\x", hex_digit, hex_digit ;
escaped_wchar = "\u", hex_digit, hex_digit, hex_digit, hex_digit, hex_digit, hex_digit, hex_digit, hex_digit ;
escaped_quote = "\'" ;
escaped_double_quote = '\"' ;

eof = ? physical end of file ? ;
\end{lstlisting}

\chapter{Syntax}

A source file, once converted into a sequence of tokens, is then converted into a tree of tokens. The provided grammar is context sensitive, and requires at least two passes to parse, since there are disambiguation rules depending on information about the declaration site of a token. However, other than the disambiguation rules, the grammar is capable of LL(1) parsing. As with the lexing phase, any deviations from the grammar must result in a diagnostic message being issued.

The grammar for a file, without disambiguation rules, is given below. This grammar uses the definitions for given in the lexicon.

\begin{lstlisting}[breaklines=true]
file = module_name, { import }, { function | variable_definition | declaration } ;

module_name = "module", ( identifier | scoped_identifier ), ";" ;
import = "import", ( identifier | scoped_identifier ), ";" ;

declaration = function_declaration
            | variable_declaration
            | struct_declaration
            | struct_forward_declaration
            | union_declaration
            | union_forward_declaration
            | enum_declaration
            | enum_forward_declaration
            | typedef_declaration
            | typedef_forward_declaration
            ;

function_declaration = type, identifier, "(", [ type, [ identifier ], [ "=", literal ], { ",", type, [ identifier ], [ "=", literal ] } ], ")", ";" ;
variable_declaration = type, identifier, { ",", identifier }, ";" ;
struct_declaration = "struct", identifier, "{", field_declaration, { field_declaration }, "}", ";" ;
struct_forward_declaration = "struct", identifier, ";" ;
union_declaration = "union", identifier, "{", field_declaration, { field_declaration }, "}", ";" ;
union_forward_declaration = "union", identifier, ";" ;
enum_declaration = "enum", identifier, "{", identifier, [ "=", extended_int_literal ], { ",", identifier }, [ "," ], "}", ";", ;
enum_forward_declaration = "enum", identifier, ";" ;
typedef_declaration = "typedef", type, identifier, ";" ;
typedef_forward_declaration = "typedef", identifier, ";" ;
field_declaration = type, identifier, { ",", identifier }, ";" ;

function = type, identifier, "(", [ type, [ identifier, [ "=", literal ] ] ], { ",", type, [ identifier, [ "=", literal ] ] } ], ")", compound_statement ;
variable_definition = type, identifier, [ "=", literal ], { ",", identifier, [ "=", literal ] }, ";" ;

statement = compound_statement
          | if_statement
          | while_statement
          | do_while_statement
          | for_statement
          | switch_statement
          | break_statement
          | continue_statement
          | return_statement
          | asm_statement
          | variable_declaration_statement
          | struct_declaration
          | struct_forward_declaration
          | union_declaration
          | union_forward_declaration
          | enum_declaration
          | enum_forward_declaration
          | typedef_declaration
          | expression, ";"
          | ";"
          ;
compound_statement = "{", { statement }, "}" ;
if_statement = "if", "(", expression, ")", statement, [ "else", statement ] ;
while_statement = "while", "(", expression, ")", statement ;
do_while_statement = "do", statement, "while", "(", expression, ")" ;
for_statement = "for", "(", [ variable_declaration_statement | expression, ";" ], expression, ";", [ expression ], ")", statement ;
switch_statement = "switch", "(", expression, ")", "{", { "case", extended_int_literal, ":", { "case", extended_int_literal, ":" }, statement | "default", ":", statement }, "}" ;
break_statement = "break", ";" ;
continue_statement = "continue", ";" ;
return_statement = "return", [ expression ], ";" ;
variable_declaration_statement = type, identifier, [ "=", assignment_expression ], { ",", identifier, [ "=", assignment_expression ] }, ";" ;
asm_statement = "asm", string_literal, ";" ;
expression = assignment_expression
           | assignment_expression, ",", expression
           ;
assignment_expression = ternary_expression
                      | ternary_expression, "=", assignment_expression
                      | ternary_expression, "*=", assignment_expression
                      | ternary_expression, "/=", assignment_expression
                      | ternary_expression, "%=", assignment_expression
                      | ternary_expression, "+=", assignment_expression
                      | ternary_expression, "-=", assignment_expression
                      | ternary_expression, "<<=", assignment_expression
                      | ternary_expression, ">>=", assignment_expression
                      | ternary_expression, ">>>=", assignment_expression
                      | ternary_expression, "&=", assignment_expression
                      | ternary_expression, "^=", assignment_expression
                      | ternary_expression, "|=", assignment_expression
                      | ternary_expression, "&&=", assignment_expression
                      | ternary_expression, "||=", assignment_expression
                      ;
ternary_expression = logical_expression
                   | logical_expression, "?", expression, ":", ternary_expression
                   ;
logical_expression = bitwise_expression, { ( "&&" | "||" ), bitwise_expression } ;
bitwise_expression = equality_expression, { ( "&" | "|" | "^" ), equality_expression } ;
equality_expression = comparison_expression, { ( "==" | "!=" ), comparison_expression } ;
comparison_expression = spaceship_expression, { ( "<" | ">" | "<=" | ">=" ), spaceship_expression } ;
spaceship_expression = shift_expression, { "<=>", shift_expression } ;
shift_expression = addition_expression, { ( "<<" | ">>" | ">>>" ), addition_expression } ;
addition_expression = multiplication_expression, { ( "+" | "-" ), multiplication_expression } ;
multiplication_expression = prefix_expression, { ( "*" | "/" | "%" ), prefix_expression } ;
prefix_expression = postfix_expression
                  | "*", prefix_expression
                  | "&", prefix_expression
                  | "++", prefix_expression
                  | "--", prefix_expression
                  | "-", prefix_expression
                  | "!", prefix_expression
                  | "~", prefix_expression
                  ;
postfix_expression = primary_expression, { ( ( "." | "->" ), identifier | "(", argument_list, ")" | "[", expression, "]" | "++" | "--") } ;
primary_expression = scoped_identifier
                   | identifier
                   | literal
                   | "cast", "[", type, "]", "(", expression, ")"
                   | "sizeof", "(", ( expression | type ), ")"
                   | "(", expression, ")"
                   ;
argument_list = [ assignment_expression, { ",", assignment_expression } ] ;
aggregate_initializer = "[", [ literal, { ",", literal } ], "]" ;
extended_int_literal = int_literal
                     | char_literal
                     | wchar_literal
                     | scoped_identifier
                     ;
literal = int_literal
        | float_literal
        | string_literal
        | char_literal
        | wstring_literal
        | wchar_literal
        | "true"
        | "false"
        | "null"
        | scoped_identifier
        | aggregate_initializer
        ;

type = "void"
     | "ubyte"
     | "byte"
     | "char"
     | "ushort"
     | "short"
     | "uint"
     | "int"
     | "wchar"
     | "ulong"
     | "long"
     | "float"
     | "double"
     | "bool"
     | identifier
     | scoped_identifier
     | type, "const"
     | type, "volatile"
     | type, "[", int_literal, "]"
     | type, "*"
     | type, "(", [ type, { ",", type } ], ")"
     ;

scoped_identifier = identifier, "::", identifier, { "::", identifier } ;
\end{lstlisting}

\section{Disambiguation}

The above grammar is intended to contain one ambiguity - without context, it is not possible to determine if an encountered identifier or scoped identifier starts a variable declaration statement or if it starts an expression (in some cases it is impossible to determine if an encountered statement is a variable declaration statement or an expression statement). As such, the parser must determine if the encountered identifier or scoped identifier is a type, and if it is a type, parse a variable declaration statement.

\section{Additional Context Requirements}

In addition to the restrictions placed by the grammar above:
\begin{itemize}
	\item no function definitions may exist within a declaration file,
	\item no function definition or declaration may have an optional argument (\texttt{"=", literal}) before a non-optional argument,
	\item no break statement may exist unless in the body of a loop or switch,
	\item no continue may exist unless in the body of a loop.
\end{itemize}

If a source file violates any of these requirements, a diagnostic message must be issued.

\chapter{Modules}

In T, a program is comprised of a series of modules, linked together. A module is described by its declaration file and its implementation. This implementation may be a code file, or a linkable file that contains the translation of a code file. Modules have a one-to-one correspondence with declaration files, and a one-to-many correspondence with code files. A translation including a linkable file shall be equivalent to one involving the original code files if no diagnostic messages are issued for the original code files. A module contains a set of declarations and a set of function definitions.

\section{Scopes}

Scopes are a mechanism to control the visibility of identifiers. A scope is a container for declarations and their identifiers, and may nest. All identifier names within a scope must be unique, but identifier names from outer scopes are shadowed by identifier names in the current scope, and identifiers from inner scopes are not visible. A file defines two scopes: the import scope, and the file scope. The file scope resides within the import scope, and in code files, automatically contains the identifiers declared in its corresponding declaration file, both as a plain identifier and a scoped identifier. Other ways of starting a scope are discussed alongside the relevant syntactic constructs. Normally, identifiers in a scope are only visible after they are declared, but within a file scope, identifiers are visible throughout the whole scope.\footnote{The ordering is irrelevant for import scopes, since there is no possibility of using anything imported in the middle of the imports.}

\subsection{Imports}

Modules may import other modules. This means that the identifiers from the module are made visible in the importing module's import scope, both as a scoped identifier consisting of the imported module name followed by the imported identifier, and as the plain identifier. If two imported identifiers collide in the import scope as plain identifiers, neither is imported as a plain identifier. If there is still a collision between the scoped identifiers, then a diagnostic is to be issued\footnote{This is to make the imported identifiers always visible, but there still exists the possibility of a collision - if module \texttt{foo} has an enumeration called \texttt{bar} with an element \texttt{baz}, then the module \texttt{foo::bar} with an identifier \texttt{bar} would collide. Since the modules sharing a prefix are probably written as part of the same library, the potential for such a collision is considered as bad code style by the authors.}.

\section{Module Header}

Each module begins with a module line, that sets the name of the module. Module names are completely independent of file name. If a code file and a declaration file share this name, the code file is considered the implementation for the declaration file. After the module line, each file has a list of modules that it imports into its import scope.

\section{Module Body}

A module body consists of either a set of declarations (for declaration files), or a set of declarations and definitions (for code files). In either case, an empty set is permissible.

\subsection{Declaration Files}

In declaration files, the set of declarations is the public interface for the module. Any code file importing the declaration file will have these identifiers available in the import scope, and any code file will have these identifiers available in the file scope.

\subsection{Code Files}

In a code file, declarations are not visible outside of the file. However, definitions for the declarations in the module may be supplied. Definitions may only be supplied in a code file. A definition for an identifier must define that identifier.

\chapter{Types}

T is a statically typed language. This means that every variable has a type associated with it, and every function has a signature associated with it, and that these types and signatures are known and checked when a module is compiled. Types determine the semantics of operations on a value of that type.

\section{Basic Data Types}

T has several basic data types, listed below. These types are named in their corresponding keyword. The execution environment must be capable of supporting all data types listed below, or else the execution environment is considered non-standard. It is required for a compiler to issue a diagnostic message if compiling to a non-standard environment when encountering an unsupported type.

\begin{itemize}
	\item \texttt{void}: indicates a value of no type. This type is only used to construct other types, and is not valid on its own. This type has a size of one byte.
	
	\item \texttt{ubyte}: an unsigned integral value, one byte wide. It is assumed that bytes contain eight bits.
	
	\item \texttt{byte}: a 2's complement signed integral value, one byte wide.
	
	\item \texttt{char}: an unsigned integral value of sufficient width to contain one byte, and the narrowest character(s) within the execution environment's character set\footnote{Generally, this is one byte wide on Unicode systems.}.
	
	\item \texttt{ushort}: an unsigned integral value, two bytes wide.
	
	\item \texttt{short}: an 2's complement signed integral value, two bytes wide.
	
	\item \texttt{ushort}: an unsigned integral value, two bytes wide.
	
	\item \texttt{short}: an 2's complement signed integral value, two bytes wide.
	
	\item \texttt{uint}: an unsigned integral value, four bytes wide.
	
	\item \texttt{int}: an 2's complement signed integral value, four bytes wide.
	
	\item \texttt{wchar}: an unsigned integral value of sufficient width to contain the widest character(s) within the execution environment's character set\footnote{Generally, this is four bytes wide on Unicode systems.}.
	
	\item \texttt{ulong}: an unsigned integral value, eight bytes wide.
	
	\item \texttt{long}: an 2's complement signed integral value, eight bytes wide.
	
	\item \texttt{float}: an IEEE 754 binary32 floating point number.
	
	\item \texttt{double}: an IEEE 754 binary64 floating point number.
	
	\item \texttt{bool}: a boolean value. This type has a size of one byte, and stores either \texttt{true} or \texttt{false}. The representation of \texttt{true} shall be the integral value one, and the representation of \texttt{false} shall be the integral value zero.
\end{itemize}

\section{Used Defined Data Types}

\section{Derived Data Types}

Any data type may form the base of a derived data type.

\begin{itemize}
	\item \textbf{Constant}: by appending \texttt{const} to the type, a type may be turned into a constant type. A value of a constant type may not be written to directly. If a constant value is written to, a diagnostic message must be issued. If a constant value is written to indirectly (e.g. through a casted pointer), undefined behaviour results, and no diagnostic message is required. The ordering of \texttt{const} and \texttt{volatile} in a declaration is irrelevant.
	
	\item \textbf{Volatile}: by appending \texttt{volatile} to the type, a type may be turned into a volatile type. Reads and writes from and to a value of volatile type are considered side effects, and must be sequenced. The ordering of \texttt{const} and \texttt{volatile} in a declaration is irrelevant.
	
	\item \textbf{Array}: by appending an integral constant in square brackets
\end{itemize}

\chapter{Declarations}

\chapter{Defintiions}

\chapter{Statements}

\chapter{Expressions}

\end{document}
